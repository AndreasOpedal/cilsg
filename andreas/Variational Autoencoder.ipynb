{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An attempt to extend VAE by Liang et al (2018) with non-binarized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import math\n",
    "import copy\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import utils\n",
    "import models\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(941562, 3)\n",
      "(235390, 3)\n"
     ]
    }
   ],
   "source": [
    "fold_1 = pd.read_csv('fold_1.csv', index_col = 0)\n",
    "fold_2 = pd.read_csv('fold_2.csv', index_col = 0)\n",
    "fold_3 = pd.read_csv('fold_3.csv', index_col = 0)\n",
    "fold_4 = pd.read_csv('fold_4.csv', index_col = 0)\n",
    "fold_5 = pd.read_csv('fold_5.csv', index_col = 0)\n",
    "\n",
    "train_data = pd.concat([fold_1, fold_2, fold_3, fold_4])\n",
    "test_data = fold_5\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row</th>\n",
       "      <th>col</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15455</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720365</th>\n",
       "      <td>0</td>\n",
       "      <td>604</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111258</th>\n",
       "      <td>0</td>\n",
       "      <td>920</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002582</th>\n",
       "      <td>0</td>\n",
       "      <td>791</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155420</th>\n",
       "      <td>0</td>\n",
       "      <td>981</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         row  col  Prediction\n",
       "15455      0    9           5\n",
       "720365     0  604           5\n",
       "1111258    0  920           3\n",
       "1002582    0  791           3\n",
       "1155420    0  981           2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Represent data as user vectors containing ratings\n",
    "\n",
    "x_u should be a vector of length 1000 containing observed ratings and zeroes at non-observed indices. I.e. want the 10000x1000 observations matrix with zero imputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ac6c30ca2a49d79b26e8a075cf1057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=941562.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = np.zeros([10000,1000])\n",
    "\n",
    "for i in tqdm(np.arange(train_data.shape[0])):\n",
    "    row_ind = train_data.iloc[i,0]\n",
    "    col_ind = train_data.iloc[i,1]\n",
    "    pred = train_data.iloc[i,2]\n",
    "    train_dataset[row_ind, col_ind] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b98e115e6e84c8fb5362cae93207fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=235390.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dataset = np.zeros([10000,1000])\n",
    "\n",
    "for i in tqdm(np.arange(test_data.shape[0])):\n",
    "    row_ind = test_data.iloc[i,0]\n",
    "    col_ind = test_data.iloc[i,1]\n",
    "    pred = test_data.iloc[i,2]\n",
    "    test_dataset[row_ind, col_ind] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1000) (10000, 1000)\n",
      "0.0941562\n",
      "0.023539\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.shape, test_dataset.shape)\n",
    "print(np.count_nonzero(train_dataset)/np.size(train_dataset))\n",
    "print(np.count_nonzero(test_dataset)/np.size(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Variational Autoencoder model in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use architecture as in paper with one hidden layer\n",
    "\n",
    "Trying output layer with 1000 neurons (for 1000 movies) and no activation\n",
    "\n",
    "(In paper they use softmax to model probability of clicks for each item but we want to predict a rating, i.e.\n",
    "a regression problem)\n",
    "\n",
    "Mainly following tutorial here: https://www.tensorflow.org/tutorials/generative/cvae\n",
    "\n",
    "\n",
    "Current errors:\n",
    "- should test only on observed values in test set, not on imputed zeroes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiVAE(tf.keras.Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(MultiVAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            tf.keras.layers.InputLayer(input_shape=(1000,)),\n",
    "            tf.keras.layers.Dense(units = 600, activation = \"tanh\"),\n",
    "            tf.keras.layers.Dense(units = latent_dim + latent_dim)\n",
    "        ])\n",
    "        \n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "            tf.keras.layers.Dense(units = 600, activation = \"tanh\"),\n",
    "            tf.keras.layers.Dense(units = 1000)\n",
    "        ])\n",
    "    \n",
    "    @tf.function\n",
    "    def sample(self, eps = None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(1, self.latent_dim)) ## This is 100 in TF tutorial? Why?\n",
    "        return self.decode(eps) \n",
    "    \n",
    "    def encode(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "    \n",
    "    def reparameterize(self, mean, logvar):\n",
    "        eps = tf.random.normal(shape = mean.shape)\n",
    "        return eps * tf.exp(logvar * .5) + mean\n",
    "    \n",
    "    def decode(self, z):\n",
    "        output = self.decoder(z)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.math.log(2. * np.pi)\n",
    "    return tf.reduce_sum(\n",
    "        -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi), axis=raxis)\n",
    "\n",
    "\n",
    "# ELBO term as combination of mse and regularized KL-term\n",
    "def compute_loss(model, x, beta):\n",
    "    mean, logvar = model.encode(x)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    x_pred = model.decode(z)\n",
    "    x_pred = tf.cast(x_pred, dtype = tf.float64)\n",
    "    \n",
    "    mse = tf.math.reduce_sum((x - x_pred)**2)/tf.cast(tf.size((x - x_pred)**2), dtype = tf.float64) # tf.keras.losses.MSE was giving strange results\n",
    "    #mse = np.mean((x - x_pred)**2)\n",
    "    kld = tf.reduce_mean(-0.5 * tf.reduce_sum(1 + logvar - mean**2 - tf.exp(logvar), axis=1), axis = 0)\n",
    "    kld = tf.cast(kld, dtype = tf.float64)\n",
    "    return mse + beta*kld\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, x, optimizer, beta):\n",
    "    \"\"\"\n",
    "    Executes one training step and returns the loss.\n",
    "    This function computes the loss and gradients, and uses the latter to\n",
    "    update the model's parameters.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_loss(model, x, beta)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100 # as in paper\n",
    "\n",
    "model = MultiVAE(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prediction(model, test_user):\n",
    "    mean, logvar = model.encode(test_user)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    predictions = model.sample(z)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training without beta/KL annealing\n",
    "\n",
    "def train_model(model, train_dataset, epochs, beta):\n",
    "    '''\n",
    "    Train this after determining beta through annealing\n",
    "    '''\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        for train_x in train_dataset:\n",
    "            train_step(model, train_x, optimizer, beta)\n",
    "            \n",
    "# Training with beta/KL annealing\n",
    "# See section 2.2.2 in paper\n",
    "def train_model_annealing(model, train_dataset, validation_dataset, epochs, anneal_beta = 1):\n",
    "    '''\n",
    "    Pick beta for which the optimal rmse is reached on the validation set and train again with this anneal_beta\n",
    "    Trains model and returns array of losses and rmse metric\n",
    "    '''\n",
    "    losses = np.array([])\n",
    "    rmse = np.array([])\n",
    "    beta = 0\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        for train_x in train_dataset:\n",
    "            train_step(model, train_x, optimizer, beta)\n",
    "        \n",
    "        epoch_loss = np.array([])\n",
    "        epoch_mse = np.array([])\n",
    "        ## ERROR IN THIS LOOP\n",
    "        ## Should only test on observed values\n",
    "        for validation_x in validation_dataset:\n",
    "            epoch_loss = np.append(epoch_loss, compute_loss(model, validation_x, beta))\n",
    "            predictions = generate_prediction(model, validation_x)\n",
    "            epoch_mse = np.append(epoch_mse, mean_squared_error(validation_x, predictions))\n",
    "        \n",
    "        losses = np.append(losses, np.mean(epoch_loss))\n",
    "        rmse = np.append(rmse, np.sqrt(np.mean(epoch_mse)))\n",
    "        \n",
    "        # Monotonically increase beta from 0 to anneal_beta\n",
    "        beta = (epoch / epochs) * anneal_beta\n",
    "    \n",
    "    return losses, rmse\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: need to convert to tensor before training\n",
    "\n",
    "tf_train = tf.convert_to_tensor(train_dataset[np.newaxis,...])\n",
    "tf_test = tf.convert_to_tensor(test_dataset[np.newaxis,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 13 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:8 out of the last 14 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:9 out of the last 15 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 16 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7fd16c421200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.53690468,  1.04528553,  1.5474204 ,  2.04460394,  2.53800978,\n",
       "         3.02720174,  3.51200765,  3.99158465,  4.46678131,  4.93513123,\n",
       "         5.39812809,  5.85494154,  6.30487348,  6.74731756,  7.18409595,\n",
       "         7.61418885,  8.03754725,  8.45428805,  8.86396897,  9.26755031,\n",
       "         9.66327738, 10.05107731, 10.43106905, 10.80238853, 11.16417875,\n",
       "        11.51655099, 11.85896285, 12.19134453, 12.51309526, 12.82417238,\n",
       "        13.12579452, 13.41625782, 13.69662183, 13.96667426, 14.22598532,\n",
       "        14.47524586, 14.71421529, 14.94293638, 15.16187555, 15.37183358,\n",
       "        15.57232708, 15.76452056, 15.94803547, 16.12338095, 16.29014647,\n",
       "        16.44925392, 16.60053497, 16.74315131, 16.87915908, 17.00718397]),\n",
       " array([0.73291583, 0.7313737 , 0.73026982, 0.72895068, 0.72807288,\n",
       "        0.72644675, 0.72526554, 0.72393495, 0.72242   , 0.7212948 ,\n",
       "        0.71968825, 0.71860484, 0.71747353, 0.71606266, 0.71474266,\n",
       "        0.71332228, 0.71204709, 0.71053558, 0.70960702, 0.70838524,\n",
       "        0.707409  , 0.70613306, 0.70531491, 0.70393683, 0.70259087,\n",
       "        0.7020783 , 0.70099643, 0.69971799, 0.69887037, 0.69796577,\n",
       "        0.69665974, 0.69592558, 0.69510275, 0.69422339, 0.69303717,\n",
       "        0.69235829, 0.69145164, 0.69039559, 0.68950816, 0.68853187,\n",
       "        0.68746493, 0.68642743, 0.68564356, 0.68491635, 0.68395734,\n",
       "        0.68304039, 0.68237756, 0.68139825, 0.68031781, 0.67979807]))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model_annealing(model, tf_train, tf_test, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1000), dtype=float32, numpy=\n",
       "array([[-4.94102128e-02, -2.88863247e-03,  1.78602472e-01,\n",
       "        -3.41955572e-01, -3.26657653e-01,  8.76727998e-02,\n",
       "         2.27693636e-02, -1.61580592e-01, -9.41136628e-02,\n",
       "        -7.49104545e-02, -5.57398722e-02,  3.57925057e-01,\n",
       "         2.88915128e-01, -5.22286057e-01, -8.59896690e-02,\n",
       "        -2.21987754e-01,  2.48619348e-01,  1.66729555e-01,\n",
       "        -4.78276312e-01, -2.48326346e-01, -4.67828631e-01,\n",
       "        -1.08001694e-01, -2.65863717e-01, -1.20846629e-01,\n",
       "         5.29498100e-01, -2.80808568e-01, -1.03622481e-01,\n",
       "        -3.56401294e-01,  2.71313965e-01,  1.60622954e-01,\n",
       "         5.04061460e-01,  2.15388700e-01, -2.39580393e-01,\n",
       "         1.21649802e-02,  5.27485490e-01,  1.01203909e-02,\n",
       "         4.34294283e-01,  3.30967695e-01,  9.44079012e-02,\n",
       "        -2.26312160e-01,  1.67598769e-01,  2.74378210e-02,\n",
       "         2.55852014e-01, -3.50164980e-01,  3.66278917e-01,\n",
       "        -3.29786152e-01,  2.49628156e-01,  4.24291909e-01,\n",
       "         4.64177504e-02, -8.06976736e-01,  6.64790511e-01,\n",
       "        -2.00486004e-01,  2.77902544e-01, -5.46103299e-01,\n",
       "         1.68545209e-02,  1.24398887e-01, -2.35423997e-01,\n",
       "        -2.41243228e-01, -1.93706170e-01, -9.45336744e-02,\n",
       "        -5.64149797e-01, -1.31511882e-01,  1.60863578e-01,\n",
       "        -2.23869324e-01, -3.05791497e-01,  5.86068392e-01,\n",
       "        -3.76920626e-02,  1.89681388e-02,  2.83590585e-01,\n",
       "         8.70075226e-02,  1.35732681e-01,  1.80702321e-02,\n",
       "        -1.96310654e-01, -2.77417094e-01, -1.53657109e-01,\n",
       "         2.97775626e-01, -2.63307691e-01,  6.37092302e-03,\n",
       "         8.54478106e-02,  1.19216889e-01, -1.20209411e-01,\n",
       "         4.75535765e-02,  5.03279626e-01, -2.91949779e-01,\n",
       "        -9.13603306e-02, -2.01984704e-01,  7.30868578e-02,\n",
       "        -3.04325297e-02, -4.65121120e-02,  6.21073544e-01,\n",
       "        -4.72022027e-01, -1.85849503e-01, -9.22436595e-01,\n",
       "        -1.72606006e-01, -8.26422870e-02,  2.61557251e-02,\n",
       "        -8.72095972e-02,  5.49650984e-03, -2.69582421e-01,\n",
       "        -4.41009134e-01, -2.13796780e-01, -3.17569852e-01,\n",
       "         2.78833024e-02,  1.28140152e-01, -4.12451714e-01,\n",
       "         1.71316937e-01, -2.25120589e-01,  4.85336855e-02,\n",
       "         2.62070358e-01, -1.71404436e-01, -1.86909307e-02,\n",
       "         4.52194273e-01,  1.21083915e-01,  2.63246357e-01,\n",
       "         1.78370148e-01,  6.03917576e-02,  8.17334205e-02,\n",
       "         2.27770153e-02,  3.62116277e-01,  1.52820438e-01,\n",
       "         1.70674697e-01,  2.69614369e-01,  1.65860176e-01,\n",
       "         4.96974677e-01, -3.01615931e-02, -5.65726720e-02,\n",
       "        -1.68380603e-01,  4.56753895e-02, -8.46843794e-03,\n",
       "        -2.31215641e-01, -8.08038637e-02, -2.20504954e-01,\n",
       "        -1.63029462e-01, -4.73063976e-01, -5.36732301e-02,\n",
       "        -3.79675031e-01, -1.39054522e-01, -7.07650304e-01,\n",
       "        -2.52194047e-01, -4.15795386e-01, -4.49810326e-01,\n",
       "        -3.05980593e-01,  2.17316970e-01, -2.04101622e-01,\n",
       "         5.87431304e-02, -3.16622145e-02, -2.84268230e-01,\n",
       "         1.55727535e-01,  1.39841046e-02, -1.41078264e-01,\n",
       "         3.00418556e-01,  4.60433960e-02,  1.47947550e-01,\n",
       "         3.37965697e-01, -1.95729598e-01, -1.13720216e-01,\n",
       "        -1.78814292e-01, -5.49369872e-01,  3.03868473e-01,\n",
       "        -1.65416613e-01, -4.27038521e-01, -4.25346419e-02,\n",
       "         6.69808835e-02, -2.83384919e-01,  5.17758548e-01,\n",
       "        -1.29539415e-01, -1.68685779e-01, -5.43820083e-01,\n",
       "         2.59479862e-02, -7.28242695e-02, -4.95550394e-01,\n",
       "        -2.33468562e-02, -3.70222479e-02, -2.74020255e-01,\n",
       "        -2.96996415e-01,  7.82738551e-02,  5.77793300e-01,\n",
       "        -5.44535160e-01,  5.12943923e-01, -4.44240510e-01,\n",
       "        -1.80755109e-01,  1.41270593e-01, -9.07019734e-01,\n",
       "        -2.13635694e-02,  5.01879513e-01, -6.23853981e-01,\n",
       "         1.80348799e-01, -2.59878367e-01,  7.42785931e-02,\n",
       "        -1.08095594e-02,  6.05727375e-01, -6.57809377e-02,\n",
       "         2.21364573e-01,  3.15605611e-01, -1.66654168e-03,\n",
       "        -7.56435096e-02, -5.94058186e-02,  4.49634314e-01,\n",
       "         1.05827220e-01,  1.35719804e-02,  3.98215428e-02,\n",
       "         3.97032052e-01,  1.12475529e-01,  2.44812027e-01,\n",
       "         9.96361207e-03,  1.53132081e-02,  4.38784361e-02,\n",
       "        -5.67323804e-01, -4.20538604e-01, -5.04019320e-01,\n",
       "        -2.10767752e-03, -1.99661314e-01, -1.93766318e-04,\n",
       "         1.94834918e-01,  5.10926664e-01, -5.71569763e-02,\n",
       "        -2.80490339e-01, -1.42278507e-01, -3.79451782e-01,\n",
       "        -2.87178040e-01, -1.04072079e-01,  2.83694565e-01,\n",
       "        -7.99346566e-02,  3.01501989e-01,  4.20267135e-01,\n",
       "        -7.69175366e-02, -1.58591196e-01,  4.87305254e-01,\n",
       "         1.31808251e-01, -1.09131765e-02, -8.55140835e-02,\n",
       "        -1.20501824e-01, -2.00180739e-01, -1.70431539e-01,\n",
       "         1.14648342e-01,  2.27796555e-01,  3.23981643e-01,\n",
       "         5.97495854e-01,  3.33435945e-02,  2.43857969e-02,\n",
       "         5.05347133e-01,  1.19242489e-01, -6.43588603e-02,\n",
       "         4.46569055e-01,  2.25855693e-01,  5.68420738e-02,\n",
       "        -3.59243125e-01, -2.90443629e-01, -5.80016524e-02,\n",
       "        -1.76665381e-01, -1.50680803e-02, -7.31900871e-01,\n",
       "        -3.42304826e-01, -1.06254011e-01, -9.56976563e-02,\n",
       "        -4.60107923e-02,  8.69369745e-01, -7.55948871e-02,\n",
       "         8.15196633e-01, -4.26329553e-01,  5.05492270e-01,\n",
       "         1.77087694e-01,  4.73798931e-01, -2.23317236e-01,\n",
       "         4.44185287e-01,  4.27036107e-01, -1.58096477e-01,\n",
       "        -8.18952844e-02, -5.81496879e-02, -2.94998258e-01,\n",
       "        -2.32357949e-01, -3.43811631e-01, -1.68754146e-01,\n",
       "        -4.43311751e-01,  3.49887848e-01, -2.61403531e-01,\n",
       "        -3.48974578e-02,  1.16770163e-01, -3.86510164e-01,\n",
       "         1.03713170e-01, -6.60757199e-02,  1.85475927e-02,\n",
       "        -5.98273054e-02,  1.13220416e-01, -2.67592013e-01,\n",
       "        -1.54549539e-01,  7.03205168e-02, -2.14499548e-01,\n",
       "         1.65931702e-01,  7.64382780e-02, -3.14444900e-02,\n",
       "         3.86263251e-01,  3.90960366e-01,  8.75410363e-02,\n",
       "         5.17832220e-01,  1.81342229e-01,  1.88393500e-02,\n",
       "        -3.59599710e-01, -5.31358365e-03,  4.30911839e-01,\n",
       "        -3.62130135e-01, -1.99635029e-02,  3.62655163e-01,\n",
       "         2.69250870e-01,  3.65024924e-01,  3.89533155e-02,\n",
       "         1.97975993e-01, -2.14120418e-01, -3.12146336e-01,\n",
       "         2.68536508e-01, -1.62783489e-01, -6.33700967e-01,\n",
       "        -9.93569717e-02, -8.45751725e-03,  1.17680743e-01,\n",
       "        -1.77786365e-01, -1.07440554e-01,  9.77408141e-02,\n",
       "         3.22157145e-01,  3.22682261e-02,  1.48411006e-01,\n",
       "         5.47225475e-02, -1.07521862e-01,  2.41612270e-02,\n",
       "        -1.27532914e-01,  1.07888110e-01,  4.10495907e-01,\n",
       "        -2.98602849e-01,  8.98511186e-02, -2.31509879e-01,\n",
       "        -4.86526601e-02,  2.35552400e-01, -3.72533232e-01,\n",
       "         1.68011412e-01,  6.79519296e-01,  1.73526034e-01,\n",
       "         9.65047926e-02, -4.85147715e-01, -2.82756835e-01,\n",
       "         4.17866334e-02, -3.66985261e-01, -1.15136884e-01,\n",
       "        -2.17589550e-02, -1.65920898e-01,  6.22759610e-02,\n",
       "        -2.74638295e-01,  2.93733180e-01,  6.82225637e-03,\n",
       "         1.62006065e-01,  2.07819134e-01,  8.48190486e-02,\n",
       "        -5.39538324e-01,  3.61049734e-02, -2.92405337e-01,\n",
       "        -2.36733630e-01,  5.08974671e-01,  1.25754893e-01,\n",
       "         2.79824615e-01, -4.66829129e-02,  3.75095122e-02,\n",
       "         2.51935095e-01, -7.29379654e-02,  1.66950524e-02,\n",
       "         4.57731307e-01, -1.39118582e-01,  6.11103326e-02,\n",
       "        -4.33773339e-01,  3.06150407e-01,  1.83939695e-01,\n",
       "        -1.54650822e-01, -5.98494351e-01, -3.56170267e-01,\n",
       "         4.66455549e-01,  2.04397768e-01,  1.42909527e-01,\n",
       "         4.71903145e-01, -4.96483028e-01, -1.40788987e-01,\n",
       "        -2.86535829e-01,  5.64621747e-01, -3.00216436e-01,\n",
       "         1.39669836e-01,  7.92270713e-03,  2.30396941e-01,\n",
       "        -4.68767464e-01, -3.41519743e-01,  2.38865301e-01,\n",
       "         1.07874036e-01, -2.63612181e-01,  1.56994700e-01,\n",
       "         1.80210412e-01, -2.61083037e-01, -6.08149990e-02,\n",
       "         3.18365782e-01, -2.14329675e-01,  1.09628960e-01,\n",
       "         7.06384540e-01, -6.83961153e-01, -3.64245400e-02,\n",
       "         2.38161623e-01, -4.22951311e-01,  1.88935369e-01,\n",
       "         2.61938661e-01, -2.71398008e-01,  2.21231923e-01,\n",
       "         1.71332449e-01, -2.31887281e-01, -7.09522516e-02,\n",
       "        -2.40926355e-01,  3.28129947e-01, -5.41685186e-02,\n",
       "         3.01340014e-01,  3.22574019e-01, -8.55420977e-02,\n",
       "         6.07008040e-02,  9.99114662e-02,  4.38634977e-02,\n",
       "         8.75418484e-02, -5.17890871e-01, -1.12427417e-02,\n",
       "        -1.61933780e-01, -1.40654389e-03,  1.32970572e-01,\n",
       "        -4.15446311e-01, -1.50110096e-01,  1.74967304e-01,\n",
       "        -2.79493481e-01, -6.55327886e-02,  2.28334785e-01,\n",
       "         1.47405285e-02, -7.62536153e-02,  3.81148189e-01,\n",
       "        -4.70135920e-03, -2.88482606e-01, -4.50642169e-01,\n",
       "        -1.06432997e-01, -2.71722615e-01, -2.02376261e-01,\n",
       "         9.28027928e-02,  3.06541115e-01,  4.85823274e-01,\n",
       "         4.11686689e-01, -4.91320759e-01, -3.47668648e-01,\n",
       "        -1.26047775e-01,  3.12745459e-02,  4.53079529e-02,\n",
       "         3.14674079e-01, -1.56917349e-01,  1.44226223e-01,\n",
       "        -4.31632191e-01, -4.64884996e-01, -5.25915213e-02,\n",
       "         2.41847828e-01, -3.11622560e-01,  2.14861482e-01,\n",
       "         4.95054126e-01, -3.48066062e-01, -2.27298036e-01,\n",
       "        -7.79068768e-02,  1.84388980e-01, -1.68392092e-01,\n",
       "        -6.26971796e-02, -2.36847952e-01,  3.03601533e-01,\n",
       "        -4.13431108e-01,  4.62480634e-01,  1.66399583e-01,\n",
       "         4.64986973e-02,  2.82685608e-01, -2.62138154e-02,\n",
       "        -2.63420492e-01, -2.27669537e-01,  5.30226491e-02,\n",
       "        -4.07525390e-01,  8.77434164e-02, -2.20786288e-01,\n",
       "        -2.49157414e-01, -3.89231116e-01,  1.96653724e-01,\n",
       "         1.93365753e-01,  2.36423433e-01, -5.65721095e-02,\n",
       "        -1.54900804e-01,  1.74639985e-01,  1.01183318e-02,\n",
       "         9.29809585e-02,  2.67123759e-01, -3.05751592e-01,\n",
       "        -5.93960583e-01, -5.13341129e-01, -3.05372924e-01,\n",
       "         1.95119873e-01, -1.60068080e-01,  1.93566054e-01,\n",
       "        -1.38683692e-01, -2.28811085e-01, -3.60978628e-03,\n",
       "         3.22640985e-01, -1.00926451e-01, -2.74041444e-01,\n",
       "        -1.12568056e-02,  6.54953122e-02, -3.73224944e-01,\n",
       "        -1.66998431e-01,  3.68262827e-01,  9.43389162e-02,\n",
       "        -9.69393402e-02,  2.40144655e-01,  6.31226320e-03,\n",
       "        -2.75866747e-01, -5.98768830e-01,  2.64617920e-01,\n",
       "        -3.05203259e-01,  1.93846405e-01, -1.79653183e-01,\n",
       "         3.74137044e-01, -3.61842126e-01, -1.46823958e-01,\n",
       "         1.16507746e-01,  1.45927638e-01, -6.11049533e-02,\n",
       "         2.50678062e-01, -5.67915797e-01,  3.31447005e-01,\n",
       "        -3.16069484e-01, -2.73167640e-01, -2.16075648e-02,\n",
       "         1.27719924e-01,  4.22449291e-01, -1.78042531e-01,\n",
       "        -1.61872327e-01, -3.46200109e-01, -2.06154749e-01,\n",
       "         1.85263142e-01,  8.39059800e-02, -3.28914523e-01,\n",
       "         7.02349395e-02,  5.81941307e-01, -9.28047970e-02,\n",
       "        -1.93530172e-02,  1.90593332e-01, -8.19139257e-02,\n",
       "        -3.51738930e-02, -1.75534382e-01, -3.70235354e-01,\n",
       "        -2.12246671e-01, -2.95216024e-01, -2.60873318e-01,\n",
       "         3.66395146e-01,  6.12424240e-02, -2.19373807e-01,\n",
       "         2.63961345e-01, -2.53497213e-01, -2.39354223e-01,\n",
       "        -2.13991851e-01,  1.22736014e-01, -1.31563932e-01,\n",
       "         1.60541281e-01,  2.85747617e-01, -4.40158993e-01,\n",
       "        -3.41457546e-01, -3.46462339e-01,  2.06652239e-01,\n",
       "         3.48894745e-02, -3.55696350e-01, -2.94047687e-02,\n",
       "         8.21072385e-02,  2.48815447e-01, -1.21294677e-01,\n",
       "        -8.61887410e-02,  6.50051981e-02, -2.20607027e-01,\n",
       "         2.71164924e-02, -6.05880260e-01,  1.37913764e-01,\n",
       "        -2.24604644e-02, -2.47341208e-02, -2.61212327e-02,\n",
       "        -3.43055688e-02,  1.27072871e-01, -2.05774652e-03,\n",
       "         3.26074988e-01, -8.64904001e-03,  3.18542272e-01,\n",
       "         2.34694332e-01,  2.81629637e-02,  4.73938547e-02,\n",
       "         1.86787248e-02,  2.51000300e-02, -1.18541829e-02,\n",
       "        -1.17269374e-01, -8.28277543e-02,  3.73834252e-01,\n",
       "        -1.97447106e-01, -1.34634692e-02,  7.49032676e-01,\n",
       "         6.32120073e-02,  5.26204742e-02, -3.81360948e-02,\n",
       "         2.29095623e-01, -2.85920799e-01,  1.87618673e-01,\n",
       "         1.50363758e-01,  5.29836953e-01, -6.42221153e-01,\n",
       "        -2.68562049e-01,  1.75132990e-01,  7.87398219e-03,\n",
       "         5.36615439e-02, -1.89955696e-01, -5.23893714e-01,\n",
       "        -4.93454844e-01, -1.92923248e-01, -3.90342474e-01,\n",
       "         1.39844045e-01, -2.06228971e-01, -2.60684080e-02,\n",
       "         1.88481174e-02, -1.66236237e-01,  5.20720899e-01,\n",
       "        -3.00753653e-01, -9.05366540e-02, -6.63034152e-03,\n",
       "         9.08207893e-02, -4.10485595e-01, -3.70201319e-01,\n",
       "        -2.04976052e-02, -7.41753578e-01, -4.26266968e-01,\n",
       "        -2.41549596e-01, -4.14169095e-02,  5.28007984e-01,\n",
       "         7.37401769e-02, -6.12697825e-02, -3.48723382e-01,\n",
       "         3.57816696e-01, -1.38553113e-01,  3.01931560e-01,\n",
       "         1.40790075e-01, -4.58776997e-03,  5.19701131e-02,\n",
       "         3.71139050e-01,  2.37565890e-01, -3.53988588e-01,\n",
       "         7.69746304e-01,  3.97149205e-01, -2.65267849e-01,\n",
       "         3.57956648e-01,  3.11663508e-01,  2.00115651e-01,\n",
       "         1.14977360e-01, -2.49933064e-01, -1.78132281e-02,\n",
       "         4.24099743e-01, -2.33097851e-01,  2.98023261e-02,\n",
       "        -3.83777350e-01,  1.95438951e-01, -4.83717799e-01,\n",
       "        -1.94561154e-01,  1.98260382e-01,  6.09096825e-01,\n",
       "        -1.92204669e-01, -1.12401851e-01, -2.51756817e-01,\n",
       "        -3.27903964e-03, -1.04451831e-02,  3.72094274e-01,\n",
       "        -2.30997548e-01,  8.97186548e-02,  1.13123879e-01,\n",
       "        -1.56530082e-01, -2.36048236e-01,  2.23095804e-01,\n",
       "        -1.53892264e-01, -8.31765607e-02, -6.37066841e-01,\n",
       "         4.38658297e-02,  5.42990565e-01, -4.21995908e-01,\n",
       "        -4.23723131e-01,  1.91643730e-01,  2.74388194e-01,\n",
       "        -1.07768131e-02, -2.55259752e-01, -3.24275315e-01,\n",
       "         5.10801315e-01,  1.78212613e-01,  1.09718107e-02,\n",
       "        -2.57193357e-01, -1.28455371e-01, -2.72482246e-01,\n",
       "        -3.60163659e-01,  2.27881610e-01,  8.68836511e-03,\n",
       "        -7.40378276e-02, -1.00079089e-01, -2.21303731e-01,\n",
       "        -6.24289736e-02,  1.49771720e-01, -2.80775249e-01,\n",
       "        -1.02500938e-01,  5.25509045e-02,  4.07105595e-01,\n",
       "        -3.23956490e-01,  5.85616864e-02,  3.89077485e-01,\n",
       "        -2.69077629e-01, -6.68731928e-01, -2.06044316e-01,\n",
       "         1.43652678e-01,  1.19653635e-01, -3.84632170e-01,\n",
       "         3.18008631e-01,  2.70581335e-01,  1.77137867e-01,\n",
       "         6.57562837e-02,  1.88927501e-01,  1.89270228e-01,\n",
       "         8.62448663e-02,  1.76784590e-01,  1.79219749e-02,\n",
       "         3.68118197e-01, -1.75182447e-01, -2.74745822e-01,\n",
       "        -1.09726712e-01,  3.21570218e-01, -4.35321748e-01,\n",
       "         1.00020533e-02, -4.00079936e-01,  2.07709014e-01,\n",
       "        -2.62243934e-02, -2.66592437e-03,  1.17351390e-01,\n",
       "        -1.26248434e-01, -5.06516337e-01,  2.11573675e-01,\n",
       "        -5.27995050e-01, -1.18119076e-01,  1.40657872e-01,\n",
       "        -8.52675959e-02,  2.20385894e-01, -7.41323307e-02,\n",
       "        -4.66974318e-01, -3.16671729e-01,  4.87701828e-03,\n",
       "         4.12230611e-01,  7.38101676e-02,  2.41705682e-02,\n",
       "         4.04187560e-01, -2.78864682e-01, -5.75271212e-02,\n",
       "         4.40851226e-02,  2.72382379e-01,  2.46496871e-01,\n",
       "        -4.03271802e-03,  2.44201779e-01,  2.33038932e-01,\n",
       "        -1.65290222e-01, -3.35360467e-01, -6.42795861e-02,\n",
       "        -1.71101719e-01, -3.36757869e-01, -1.32145941e-01,\n",
       "         5.83951250e-02,  3.74003639e-03, -1.26549527e-01,\n",
       "         1.59969077e-01, -5.96826077e-02,  4.02430892e-01,\n",
       "        -2.36230224e-01, -2.17347413e-01, -2.12238148e-01,\n",
       "         8.63663033e-02, -4.49047536e-01, -5.11638634e-02,\n",
       "        -1.07874207e-01,  6.34136498e-02, -2.98515290e-01,\n",
       "        -9.63923186e-02, -2.93385595e-01,  4.56665158e-01,\n",
       "         3.20682645e-01, -3.44001442e-01, -2.80712992e-01,\n",
       "         2.31889095e-02, -1.56073645e-01,  1.15747396e-02,\n",
       "         2.87779003e-01, -1.45284057e-01, -1.55625358e-01,\n",
       "        -2.04938665e-01,  6.44914746e-01, -1.14057772e-02,\n",
       "         1.69100583e-01, -3.44044417e-01, -2.43922904e-01,\n",
       "        -1.79880232e-01,  2.02392668e-01, -7.22689629e-01,\n",
       "        -2.30037775e-02, -4.73621264e-02, -7.78001100e-02,\n",
       "        -1.90367207e-01, -1.12846576e-01,  1.01924218e-01,\n",
       "         2.17313945e-01, -4.63236839e-01,  1.64063245e-01,\n",
       "         3.82069051e-01,  6.17689937e-02,  2.09142178e-01,\n",
       "        -2.00854614e-01,  3.14191133e-01,  1.97903857e-01,\n",
       "         5.23688853e-01, -3.42326701e-01,  3.12715113e-01,\n",
       "        -1.62060171e-01, -3.75924766e-01, -1.20522633e-01,\n",
       "        -2.84729693e-02,  6.46919489e-01,  8.52101505e-01,\n",
       "         1.44103616e-01, -7.54790783e-01, -1.43136857e-02,\n",
       "         4.67497855e-04, -2.49890864e-01,  1.81125671e-01,\n",
       "        -3.44829917e-01,  4.78996515e-01,  5.63497126e-01,\n",
       "        -8.44958603e-01,  5.05804420e-01,  2.91571468e-01,\n",
       "         3.43841583e-01,  1.08935334e-01,  2.64584184e-01,\n",
       "        -9.70566180e-04, -3.95160317e-01,  9.86771882e-02,\n",
       "        -2.49205813e-01, -6.39942735e-02, -3.54925960e-01,\n",
       "         7.54676908e-02,  1.36864230e-01, -3.15395355e-01,\n",
       "         1.10446617e-01, -1.33258589e-02, -7.82006502e-01,\n",
       "        -2.95572966e-01, -1.39352739e-01,  4.80822250e-02,\n",
       "         1.62360027e-01, -8.61634910e-01, -1.80804029e-01,\n",
       "         3.18990231e-01, -3.51130188e-01,  3.66895229e-01,\n",
       "         9.76982340e-03,  4.54301178e-01, -1.85575798e-01,\n",
       "        -1.36328442e-02,  1.82560161e-01,  4.23357934e-01,\n",
       "        -4.93398793e-02,  1.74012899e-01,  3.33508432e-01,\n",
       "        -1.43173143e-01, -4.19745147e-01, -3.06413144e-01,\n",
       "        -5.77542279e-03, -2.10957408e-01, -1.15938717e-03,\n",
       "         3.80264580e-01, -1.85837433e-01, -3.40508640e-01,\n",
       "        -7.80473351e-02, -1.33717105e-01, -3.77902150e-01,\n",
       "        -6.10234320e-01, -2.55132586e-01, -2.31112242e-01,\n",
       "        -4.22250956e-01, -2.30692595e-01,  8.89571086e-02,\n",
       "        -1.58324569e-01,  2.42433906e-01, -1.56460047e-01,\n",
       "         4.65271473e-01, -7.21210167e-02, -6.08925760e-01,\n",
       "        -1.37775719e-01,  4.83720042e-02,  1.94766819e-01,\n",
       "         2.26081893e-01,  1.37748703e-01,  3.26244533e-02,\n",
       "         5.38411796e-01, -5.74758649e-01, -9.16437805e-02,\n",
       "         3.36808652e-01, -2.66244233e-01,  5.15340567e-01,\n",
       "         1.14838362e-01, -2.47950613e-01, -2.36655325e-02,\n",
       "        -2.66862720e-01,  2.41791591e-01, -1.07304171e-01,\n",
       "        -2.65427679e-01,  3.00349593e-01, -3.42075765e-01,\n",
       "         2.51992941e-01,  5.58590591e-01, -3.76632392e-01,\n",
       "        -3.37381754e-03, -4.40727919e-02,  1.53698444e-01,\n",
       "        -7.46079236e-02,  1.14941308e-02, -3.71702909e-01,\n",
       "        -6.39833510e-01, -1.82895988e-01,  3.56278241e-01,\n",
       "         2.55686849e-01, -1.55729651e-01,  3.29323083e-01,\n",
       "        -7.87041709e-02, -1.27797276e-02, -7.66063705e-02,\n",
       "         5.67216933e-01,  3.43455493e-01, -3.30328733e-01,\n",
       "        -7.04119503e-02,  3.14086050e-01, -1.24148376e-01,\n",
       "         1.52279526e-01, -2.88746446e-01, -7.09246099e-02,\n",
       "         3.80124569e-01,  1.62769333e-01,  1.98969960e-01,\n",
       "         5.18779814e-01,  2.05649942e-01, -2.06410617e-01,\n",
       "        -2.83574671e-01,  2.07557946e-01,  1.65950790e-01,\n",
       "        -3.69240791e-01,  3.26344848e-01,  6.85050368e-01,\n",
       "        -1.10657439e-01, -3.44495356e-01, -2.81042308e-01,\n",
       "         3.70310932e-01, -1.41565442e-01, -5.31136811e-01,\n",
       "         9.86262187e-02,  4.00507361e-01,  5.99431694e-01,\n",
       "         1.50249287e-01,  4.43775147e-01, -8.61664787e-02,\n",
       "         3.94410580e-01,  4.65169579e-01, -1.23386472e-01,\n",
       "         4.09260988e-01,  1.54821858e-01,  3.04814667e-01,\n",
       "        -3.55900303e-02,  1.00493975e-01, -4.19920504e-01,\n",
       "        -5.49046636e-01,  1.39949456e-01, -5.55871380e-03,\n",
       "        -3.15129191e-01, -3.95851471e-02,  2.86227822e-01,\n",
       "         2.50022948e-01,  2.70843972e-02, -9.01049897e-02,\n",
       "         1.02767110e-01,  2.09385648e-01, -2.71914542e-01,\n",
       "         2.23871320e-01,  1.42677456e-01,  2.76593491e-02,\n",
       "         3.40464532e-01, -1.77711546e-02,  6.12069778e-02,\n",
       "        -1.59147114e-01,  2.78981775e-01, -4.68001246e-01,\n",
       "         3.75719249e-01,  1.29552886e-01,  1.39122540e-02,\n",
       "         4.58704621e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_prediction(model, tf.convert_to_tensor(train_dataset[np.newaxis,0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
