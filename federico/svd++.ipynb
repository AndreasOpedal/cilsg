{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD++ \n",
    "\n",
    "We implement a variation of the SVD++ algorithm proposed by Yehuda Koren. Specifically, we apply the following changes:\n",
    "\n",
    "- add learning rate decay\n",
    "- add momentum to the gradients\n",
    "- use heuristics to initialize user biases, item biases, and item factors as proposed by Zhengzheng Xian et al., instead of learning them in the optimization step\n",
    "\n",
    "The decay and momentum are added to stabilize the optimization, while the heuristic initializations are needed to prevent prohibitive training times.\n",
    "\n",
    "As a further way to speed-up the training process, we implement the optimization step in cython.\n",
    "\n",
    "We call this algorithm **SGDPP2**, which stands for Stochastic Gradient Descent Plus-Plus v2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'surprise'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2d43939bc4d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msurprise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAlgoBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPredictionImpossible\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'surprise'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from surprise import AlgoBase, PredictionImpossible, Reader, Dataset, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the hyperparameters\n",
    "\n",
    "We first initialize the hyperparameters for the algorithm, such as the number of latent factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent factors\n",
    "n_factors = 192\n",
    "# number of epochs\n",
    "n_epochs = 85\n",
    "# initialization Gaussian mean for matrices P, Q\n",
    "init_mean = 0.2\n",
    "# intialization Gaussian standard deviation for matrices P, Q\n",
    "init_std = 0.005\n",
    "# learning rate for matrix P, representing the users' latent features\n",
    "lr_pu = 0.005\n",
    "# learning rate for matrix Q, representing the items' latent features\n",
    "lr_qi = 0.005\n",
    "# the strenght of the gradient momentum for matrix P\n",
    "alpha_pu = 0.3\n",
    "# the strenght of the gradient momentum for matrix Q\n",
    "alpha_qi = 0.3\n",
    "# the (linear) decay rate associated with the learning rate for matrix P\n",
    "decay_pu = 0.02\n",
    "# the (linear) decay rate associated with the learning rate for matrix Q\n",
    "decay_qi = 0.05\n",
    "# the regularization strenght for matrix P\n",
    "reg_pu = 0.06\n",
    "# the regularization strenght for matrix Q\n",
    "reg_qi = 0.065\n",
    "# the regularization strenght for the initialization of the user biases\n",
    "lambda_bu = 25\n",
    "# the regularization strenght for the initialization of the item biases\n",
    "lambda_bi = 0.5\n",
    "# the regularization strenght for the initialization of the item factors\n",
    "lambda_yj = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the dataset\n",
    "\n",
    "We first read the dataset as a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_raw = pd.read_csv(file_path)\n",
    "\n",
    "# parse rows and columns\n",
    "row_str = data_train_raw['Id'].apply(lambda x: x.split('_')[0])\n",
    "row_id = row_str.apply(lambda x: int(x.split('r')[1]) - 1)\n",
    "col_str = data_train_raw['Id'].apply(lambda x: x.split('_')[1])\n",
    "col_id = col_str.apply(lambda x: int(x.split('c')[1]) - 1)\n",
    "\n",
    "# apply changes\n",
    "data_train_raw['row'] = row_id\n",
    "data_train_raw['col'] = col_id\n",
    "\n",
    "# dataset as data frame\n",
    "data_train_df = data_train_raw.loc[:,['row', 'col', 'Prediction']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training and test sets\n",
    "\n",
    "Next we prepare the training and test sets by using the surprise library, based on the previously computed DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up surprise dataset\n",
    "reader = Reader()\n",
    "dataset = Dataset.load_from_df(df[['row', 'col', 'Prediction']], reader)\n",
    "\n",
    "# now set up training and test set, with a test split of 25%\n",
    "trainset, testset = train_test_split(data, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristic initialization\n",
    "\n",
    "We first initialize the user and item biases. Each entry $b_i$, $b_u$ is initialized as follows:\n",
    "\n",
    "$$b_i = \\frac{\\sum_{u\\in R(i)}(r_{ui}-\\mu)}{\\lambda_{bi} + |R(i)|}$$\n",
    "$$b_u = \\frac{\\sum_{i\\in R(u)}(r_{ui}-\\mu-b_i)}{\\lambda_{bu} + |R(u)|}$$\n",
    "\n",
    "where $R(u)$ is the set of items rated by user $u$, and viceversa.\n",
    "\n",
    "The item factors are initialized as follows:\n",
    "\n",
    "$$Y_u = \\frac{\\sum_{i\\in R(u)}V_i}{\\sqrt{|R(u)|}(\\lambda_{yj} + |R(u)|)}$$\n",
    "\n",
    "where $V \\in R^{items\\times factors}$ is the items-to-factors matrix obtained from SVD. Note that for this step we do not impute the ratings matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
