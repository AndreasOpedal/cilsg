{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD++ \n",
    "\n",
    "We implement a variation of the SVD++ algorithm proposed by Yehuda Koren. SVD++ computes the estimate for rating $r_{ui}$ as follows:\n",
    "\n",
    "$$\\hat{r}_{ui} = b_{ui} + q_i^T\\Bigg(p_u + |N(u)|^{-\\frac{1}{2}} \\sum_{j\\in N(U)} y_j \\Bigg)$$\n",
    "\n",
    "where $b_{ui}$ represent the bias of item $i$ for user $u$, and $\\sum y_j$ represents the implicit feedback for user $u$.\n",
    "\n",
    "We apply the following changes:\n",
    "\n",
    "- add learning rate decay\n",
    "- add momentum to the gradients\n",
    "- use heuristics to initialize user biases, item biases, and users' implicit feedback as proposed by Zhengzheng Xian et al., instead of learning them in the optimization step\n",
    "\n",
    "The decay and momentum are added to stabilize the optimization, while the heuristic initializations are needed to prevent prohibitive training times.\n",
    "\n",
    "As a further way to speed-up the training process, we implement the optimization step in cython.\n",
    "\n",
    "We call this algorithm **SGDPP2**, which stands for Stochastic Gradient Descent Plus-Plus v2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-surprise in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (1.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-surprise) (0.14.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-surprise) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.11.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-surprise) (1.17.3)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-surprise) (1.3.1)\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%pip install scikit-surprise\n",
    "from surprise import AlgoBase, PredictionImpossible, Reader, Dataset, accuracy\n",
    "from surprise.model_selection import train_test_split, cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the dataset\n",
    "\n",
    "First we read the dataset as a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_raw = pd.read_csv('../data/data_train.csv')\n",
    "\n",
    "# parse rows and columns\n",
    "row_str = data_train_raw['Id'].apply(lambda x: x.split('_')[0])\n",
    "row_id = row_str.apply(lambda x: int(x.split('r')[1]) - 1)\n",
    "col_str = data_train_raw['Id'].apply(lambda x: x.split('_')[1])\n",
    "col_id = col_str.apply(lambda x: int(x.split('c')[1]) - 1)\n",
    "\n",
    "# apply changes\n",
    "data_train_raw['row'] = row_id\n",
    "data_train_raw['col'] = col_id\n",
    "\n",
    "# dataset as data frame\n",
    "data_train_df = data_train_raw.loc[:,['row', 'col', 'Prediction']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training and test sets\n",
    "\n",
    "Next we prepare the training and test sets by using the surprise package, based on the previously computed DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up surprise dataset\n",
    "reader = Reader()\n",
    "dataset = Dataset.load_from_df(data_train_df[['row', 'col', 'Prediction']], reader)\n",
    "\n",
    "# now set up training and test set, with a test split of 25%\n",
    "trainset, testset = train_test_split(dataset, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristic initialization\n",
    "\n",
    "Now we initialize the user and item biases. Each entry $b_i$, $b_u$ is initialized as follows:\n",
    "\n",
    "$$b_i = \\frac{\\sum_{u\\in R(i)}(r_{ui}-\\mu)}{\\lambda_{bi} + |R(i)|}$$ \\\n",
    "$$b_u = \\frac{\\sum_{i\\in R(u)}(r_{ui}-\\mu-b_i)}{\\lambda_{bu} + |R(u)|}$$\n",
    "\n",
    "where $R(u)$ is the set of items rated by user $u$, and viceversa.\n",
    "\n",
    "The implicit feedback for user $u$ is initialized as follows:\n",
    "\n",
    "$$Y_u = \\frac{\\sum_{i\\in R(u)}V_i}{\\sqrt{|R(u)|}(\\lambda_{yj} + |R(u)|)}$$\n",
    "\n",
    "where $V \\in \\mathbb{R}^{items\\times factors}$ is the items-to-factors matrix obtained from SVD. Note that for this step we do not impute the ratings matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_heuristics(n_factors, lambda_bu, lambda_bi, lambda_yj):\n",
    "    '''\n",
    "    Compute the global mean, users' biases, items' biases, and users' implicit feedback.\n",
    "    \n",
    "    Parameters:\n",
    "    n_factors (int): the number of latent factors\n",
    "    lambda_bu (float): the regularization strenght for the initialization of the user biases\n",
    "    lambda_bi (float): the regularization strenght for the initialization of the item biases\n",
    "    lambda_yj (float): the regularization strenght for the initialization of the user implicit feedback\n",
    "    \n",
    "    Returns:\n",
    "    mu, bias_u, bias_i, Y (float, numpy.ndarray, numpy.ndarray, numpy.ndarray): the computed heuristics\n",
    "    '''\n",
    "    \n",
    "    print('Computing heuristics...')\n",
    "\n",
    "    # get global mean\n",
    "    mu = trainset.global_mean\n",
    "\n",
    "    # initialize the biases vectors\n",
    "    bias_u = np.zeros(trainset.n_users)\n",
    "    bias_i = np.zeros(trainset.n_items)\n",
    "\n",
    "    # items biases\n",
    "    for i in range(trainset.n_items):\n",
    "        neigh_i = trainset.ir[i] # neighborhood for item i\n",
    "        for u, r in neigh_i:\n",
    "            bias_i[i] += r - mu\n",
    "        bias_i[i] /= (lambda_bi + len(neigh_i))\n",
    "\n",
    "    # users biases\n",
    "    for u in range(trainset.n_users):\n",
    "        neigh_u = trainset.ur[u] # neighborhood for item u\n",
    "        for i, r in neigh_u:\n",
    "            bias_u[u] += r - mu - bias_i[i]\n",
    "        bias_u[u] /= (lambda_bu + len(neigh_u))\n",
    "    \n",
    "    # initialize item factors matrix\n",
    "    Y = np.zeros((trainset.n_users,n_factors))\n",
    "\n",
    "    # create matrix for the svd (note that it not imputed)\n",
    "    X = np.zeros((trainset.n_users,trainset.n_items))\n",
    "\n",
    "    # fill X\n",
    "    for u, i, r in trainset.all_ratings():\n",
    "        X[u,i] = r\n",
    "\n",
    "    # compute the SVD for the unimputed rating matrix (i.e. 0 entries)\n",
    "    _, S, Vt = np.linalg.svd(X)\n",
    "    D = np.zeros(shape=(S.shape[0],S.shape[0])) # create diagonal matrix D\n",
    "    np.fill_diagonal(D,S) # fill D with S\n",
    "    D = np.sqrt(D) # square root of D\n",
    "    V = D.dot(Vt.T)\n",
    "    V = V[:,:n_factors] # select vectors from item-factors\n",
    "\n",
    "    # finally compute the user implicit feedback\n",
    "    for u in range(trainset.n_users):\n",
    "        neigh_u = trainset.ur[u]\n",
    "        for i, _ in neigh_u:\n",
    "            Y[u,:] += V[i,:]\n",
    "        Y[u,:] /= ((lambda_yj + len(neigh_u))*np.sqrt(len(neigh_u)))\n",
    "        \n",
    "    # return all the heuristics\n",
    "    return mu, bias_u, bias_i, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization\n",
    "\n",
    "The algorithm optimizes the following loss function:\n",
    "\n",
    "$$L_{ui} = \\Big(r_{ui}-\\mu-b_u-b_i-q_i^T\\big(p_u + Y_u\\big)\\Big)^2 + \\Big(reg_{pu}||p_u||^2 + reg_{qi}||q_i||^2\\Big) = error^2 + \\Big(reg_{pu}||p_u||^2 + reg_{qi}||q_i||^2\\Big)$$\n",
    "\n",
    "The optimization step is performed using SGD. For $p_u$, $q_i$ we have:\n",
    "\n",
    "$$p_u = p_u + alpha_{pu}\\Delta g_{pu} + lr_{pu}(error*q_i - reg_{pu}p_u$$ \\\n",
    "$$q_i = q_i + alpha_{qi}\\Delta g_{qi} + lr_{qi}(error*(p_u + Y_u) - reg_{qi}q_i)$$\n",
    "\n",
    "We now define the following function which performs the optimization steps shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(trainset, mu, bias_u, bias_i, Y, n_factors, n_epochs, init_mean, init_std, lr0_pu, lr0_qi, alpha_pu, alpha_qi, decay_pu, decay_qi, reg_pu, reg_qi):\n",
    "    '''\n",
    "    Performs the optimization via SGD.\n",
    "    \n",
    "    Parameters:\n",
    "    mu (float): the global mean\n",
    "    bias_u (numpy.ndarray): the vector of user biases\n",
    "    bias_i (numpy.ndarray): the vector of item biases\n",
    "    Y (numpy.ndarray): the matrix representing the user implicit feedback\n",
    "    n_factors (int): the number of latent factors\n",
    "    n_epochs (int): the number of epochs to perform\n",
    "    init_mean (float): the initialization Gaussian mean for matrices P, Q\n",
    "    init_std (float): the initialization Gaussian standard deviation for matrices P, Q\n",
    "    lr0_pu (float): the initial learning rate for matrix P, which represents the users' latent features\n",
    "    lr0_qi (float): the initial learning rate for matrix Q, which represents the items' latent features\n",
    "    alpha_pu (float): the strenght of the gradient momentum for matrix P\n",
    "    alpha_qi (float): the strenght of the gradient momentum for matrix Q\n",
    "    decay_pu (float): the (linear) decay rate associated with the learning rate for matrix P\n",
    "    decay_qi (float): the (linear) decay rate associated with the learning rate for matrix Q\n",
    "    reg_pu (float): the regularization strenght for matrix P\n",
    "    reg_qi (float): the regularization strenght for matrix Q\n",
    "    '''\n",
    "    \n",
    "    # initialize P, Q\n",
    "    P = np.random.normal(init_mean, init_std, (trainset.n_users,n_factors))\n",
    "    Q = np.random.normal(init_mean, init_std, (trainset.n_items,n_factors))\n",
    "    \n",
    "    # initialize gradient mometum\n",
    "    delta_g_pu = np.zeros((trainset.n_users,n_factors))\n",
    "    delta_g_qi = np.zeros((trainset.n_items,n_factors))\n",
    "    \n",
    "    # initialize vector to record training loss\n",
    "    train_rmse = np.zeros(n_epochs)\n",
    "    \n",
    "    # start optimization\n",
    "    for current_epoch in range(n_epochs):\n",
    "        print('Processing epoch {}'.format(current_epoch+1))\n",
    "        # sum of errors for current_epoch\n",
    "        err_iter = []\n",
    "        # apply decay\n",
    "        lr_pu = lr0_pu/(1 + decay_pu*current_epoch)\n",
    "        lr_qi = lr0_qi/(1 + decay_qi*current_epoch)\n",
    "        # iterate through training data\n",
    "        for u, i, r in trainset.all_ratings():\n",
    "            # compute error\n",
    "            err = r - (mu + bias_u[u] + bias_i[i] + np.dot(Q[i,:], P[u,:] + Y[u,:]))\n",
    "            # add square of error to the sum\n",
    "            err_iter.append(err**2)\n",
    "            # retain old values for P[u,:], Q[i,:]\n",
    "            pu, qi = P[u,:], Q[i,:]\n",
    "            # update momentum\n",
    "            delta_g_pu[u,:] = alpha_pu*delta_g_pu[u,:] + lr_pu*(err*qi - reg_pu*pu)\n",
    "            delta_g_qi[i,:] = alpha_qi*delta_g_qi[i,:] + lr_qi*(err*(pu + Y[u,:]) - reg_qi*qi)\n",
    "            # update P, Q\n",
    "            P[u,:] = P[u,:] + delta_g_pu[u,:]\n",
    "            Q[i,:] = Q[i,:] + delta_g_qi[i,:]\n",
    "            \n",
    "        # compute the training loss\n",
    "        train_rmse[current_epoch] = np.sqrt(sum(err_iter)/len(err_iter))\n",
    "        \n",
    "    # plot training error\n",
    "    plt.plot(range(n_epochs), train_rmse)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.title('Training RMSE')\n",
    "    plt.show\n",
    "            \n",
    "    # return learned matrices P, Q\n",
    "    return P, Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapper class\n",
    "\n",
    "To run algorithms using the surprise package, we need to create a wrapper class. This class must have the following structure:\n",
    "\n",
    "```\n",
    "class MySVDPP(Algobase):\n",
    "    def __init__(self):\n",
    "        AlgoBase.__init__(self)\n",
    "    def fit(self, trainset):\n",
    "        AlgoBase.fit(self, trainset)\n",
    "        return self\n",
    "    def estimate(self, u, i):\n",
    "        return self.prediction[u,i]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDPP2(AlgoBase):\n",
    "    \n",
    "    def __init__(self, n_factors=10, n_epochs=5, init_mean=0, init_std=0.1, lr0_pu=0.1, lr0_qi=0.1, alpha_pu=0.1, alpha_qi=0.1, decay_pu=0.1, decay_qi=0.1, reg_pu=1, reg_qi=1, lambda_bu=1, lambda_bi=1, lambda_yj=1):\n",
    "        \n",
    "        AlgoBase.__init__(self)\n",
    "        \n",
    "        self.n_factors = n_factors\n",
    "        self.n_epochs = n_epochs\n",
    "        self.init_mean = init_mean\n",
    "        self.init_std = init_std\n",
    "        self.lr0_pu = lr0_pu\n",
    "        self.lr0_qi = lr0_qi\n",
    "        self.alpha_pu = alpha_pu\n",
    "        self.alpha_qi = alpha_qi\n",
    "        self.decay_pu = decay_pu\n",
    "        self.decay_qi = decay_qi\n",
    "        self.reg_pu = reg_pu\n",
    "        self.reg_qi = reg_qi\n",
    "        self.lambda_bu = lambda_bu\n",
    "        self.lambda_bi = lambda_bi\n",
    "        self.lambda_yj = lambda_yj\n",
    "        \n",
    "    def fit(self, trainset):\n",
    "        \n",
    "        AlgoBase.fit(self, trainset)\n",
    "        \n",
    "        # compute the necessary heuristics\n",
    "        self.mu, self.bias_u, self.bias_i, self.Y = get_heuristics(self.n_factors, self.lambda_bu, self.lambda_bi, self.lambda_yj)\n",
    "        \n",
    "        # now perform SGD\n",
    "        self.P, self.Q = sgd(self.trainset, self.mu, self.bias_u, self.bias_i, self.Y, self.n_factors, self.n_epochs, self.init_mean, self.init_std, self.lr0_pu, self.lr0_qi, self.alpha_pu, self.alpha_qi, self.decay_pu, self.decay_qi, self.reg_pu, self.reg_qi)\n",
    "        \n",
    "    def estimate(self, u, i):\n",
    "        \n",
    "        # compute the estimate\n",
    "        est = self.mu + self.bias_u[u] + self.bias_i[i] + np.dot(self.Q[i,:], self.P[u,:] + self.Y[u,:])\n",
    "        \n",
    "        # clip the estimate to fall within range\n",
    "        est = np.clip(est, 1,5)\n",
    "        \n",
    "        return est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and run the model\n",
    "\n",
    "Now we are ready to create and run an instance of the *SGDPP2* algorithm. Please note that the number of latent factors and epochs chosen are way below the ones we chose to get our result, as it would take too much time otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing heuristics...\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Processing epoch 20\n",
      "Processing epoch 21\n",
      "Processing epoch 22\n",
      "Processing epoch 23\n",
      "Processing epoch 24\n",
      "Processing epoch 25\n",
      "Processing epoch 26\n",
      "Processing epoch 27\n",
      "Processing epoch 28\n",
      "Processing epoch 29\n",
      "Processing epoch 30\n",
      "Processing epoch 31\n",
      "Processing epoch 32\n",
      "Processing epoch 33\n",
      "Processing epoch 34\n",
      "Processing epoch 35\n",
      "Processing epoch 36\n",
      "Processing epoch 37\n",
      "Processing epoch 38\n",
      "Processing epoch 39\n",
      "Processing epoch 40\n",
      "Processing epoch 41\n",
      "Processing epoch 42\n",
      "Processing epoch 43\n",
      "Processing epoch 44\n",
      "Processing epoch 45\n",
      "Processing epoch 46\n",
      "Processing epoch 47\n",
      "Processing epoch 48\n",
      "Processing epoch 49\n",
      "Processing epoch 50\n",
      "Processing epoch 51\n",
      "Processing epoch 52\n",
      "Processing epoch 53\n",
      "Processing epoch 54\n",
      "Processing epoch 55\n",
      "Processing epoch 56\n",
      "Processing epoch 57\n",
      "Processing epoch 58\n",
      "Processing epoch 59\n",
      "Processing epoch 60\n",
      "Processing epoch 61\n",
      "Processing epoch 62\n",
      "Processing epoch 63\n",
      "Processing epoch 64\n",
      "Processing epoch 65\n",
      "Processing epoch 66\n",
      "Processing epoch 67\n",
      "Processing epoch 68\n",
      "Processing epoch 69\n",
      "Processing epoch 70\n",
      "Processing epoch 71\n",
      "Processing epoch 72\n",
      "Processing epoch 73\n",
      "Processing epoch 74\n",
      "Processing epoch 75\n",
      "Processing epoch 76\n",
      "Processing epoch 77\n",
      "Processing epoch 78\n",
      "Processing epoch 79\n",
      "Processing epoch 80\n",
      "Processing epoch 81\n",
      "Processing epoch 82\n",
      "Processing epoch 83\n",
      "Processing epoch 84\n",
      "Processing epoch 85\n",
      "RMSE: 0.9809\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define the model\n",
    "model = SGDPP2(n_factors=192, n_epochs=85, init_mean=0.2, init_std=0.005, lr0_pu=0.005, lr0_qi=0.005, alpha_pu=0.3, alpha_qi=0.3, decay_pu=0.02, decay_qi=0.05, reg_pu=0.06, reg_qi=0.065, lambda_bu=25, lambda_bi=0.5, lambda_yj=50)\n",
    "\n",
    "# fit the model to the training set\n",
    "model.fit(trainset)\n",
    "\n",
    "# compute the predictions\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# compute the RMSE on the testset\n",
    "rmse = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
