{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "sys.path.append('.')\n",
    "import dataset\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"../../data/data-train.csv.0\"):\n",
    "    dataset.create_n_splits(\"../../data/data-train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching dataset ../../data/data-train.csv.0 ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4351b73097b042d6bd0b57a0eb29341e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=231392.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Caching dataset ../../data/data-train.csv.1 ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e2149977f8e42c782b73814c578955a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=231392.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Caching dataset ../../data/data-train.csv.2 ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f4c149ecfd749fabd4514e9b06ce0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=231392.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Caching dataset ../../data/data-train.csv.3 ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0557cfd447c14fa88a02c9d8ba2f43c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=231391.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Caching dataset ../../data/sample-submission.csv ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe14ac3cf2745a39c95ab9aedf39e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1176952.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Caching dataset ../../data/data-train.csv.4 ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b4f25ef224492b8824ad1fc72b6094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=251385.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, X_test = dataset.load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For final submission:\n",
    "train_on_full_dataset = False\n",
    "if train_on_full_dataset:\n",
    "    X_train = X_train + X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.count_nonzero(), X_valid.count_nonzero(), X_test.count_nonzero()\n",
    "valid_indices = list(set(zip(X_train.nonzero()[0], X_train.nonzero()[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.user_dim = 10000\n",
    "        self.item_dim = 1000\n",
    "        \n",
    "        self.layer_1 = nn.Linear(1000, 100)\n",
    "        self.layer_1a = nn.Linear(100, 100)\n",
    "        \n",
    "        self.vae = nn.Linear(100, 100)\n",
    "        \n",
    "        self.layer_3 = nn.Linear(50, 100)\n",
    "        self.cls_layer = nn.Linear(100, 1000)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        net_data = data\n",
    "\n",
    "        # Encoder layers\n",
    "        net_data = F.relu(self.layer_1(net_data))\n",
    "        net_data = F.dropout(net_data, training=self.training)\n",
    "        \n",
    "        net_data = F.relu(self.layer_1a(net_data))\n",
    "        net_data = F.dropout(net_data, training=self.training)\n",
    "        \n",
    "        # VAE bottleneck\n",
    "        vae = self.vae(net_data)\n",
    "        mus_q, log_sigmas_q = torch.split(vae, 50, dim=-1)\n",
    "        stds_q = torch.exp(0.5 * log_sigmas_q)\n",
    "        \n",
    "        KL = 0.5 * (-log_sigmas_q + torch.exp(log_sigmas_q) + mus_q ** 2 - 1)\n",
    "        KL = torch.sum(KL, dim=-1)\n",
    "        KL = torch.mean(KL)\n",
    "        \n",
    "        # Sample random value if training,\n",
    "        # use the mean during evaluation\n",
    "        if not self.training:\n",
    "            sampled_z = mus_q\n",
    "        else:\n",
    "            eps = torch.randn(stds_q.shape, dtype=torch.float, device=device)\n",
    "            sampled_z = mus_q + eps * stds_q\n",
    "        \n",
    "        # Decoder layers\n",
    "        net_data = F.relu(self.layer_3(sampled_z))\n",
    "        net_data = F.dropout(net_data, training=self.training)\n",
    "        \n",
    "        # Classification layer\n",
    "        y_score = self.cls_layer(net_data)\n",
    "        return y_score, KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "model = Autoencoder().to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "925567 251385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16.037534986267808"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.count_nonzero(), X_valid.count_nonzero())\n",
    "\n",
    "def get_predictions(A):\n",
    "    \"\"\"Predict the full matrix using the autoencoder.\"\"\"\n",
    "    model.eval()\n",
    "    A_pred = np.zeros((10000, 1000))\n",
    "    valid_indices = list(set(zip(A.nonzero()[0], A.nonzero()[1])))\n",
    "    \n",
    "    # Split dataset in batches of 64 rows ...\n",
    "    for i in range(0, 10000, 64):\n",
    "        X = X_train[i:i+64].todense()\n",
    "        X_ = torch.tensor(X, dtype=torch.float, device=device)\n",
    "        y_preds, KL = model(X_)\n",
    "        \n",
    "        for i_ in range(y_preds.shape[0]):\n",
    "            x_i = y_preds[i_].detach().cpu()\n",
    "            A_pred[i+i_] = x_i\n",
    "    \n",
    "    return A_pred, valid_indices\n",
    "\n",
    "def compute_loss():\n",
    "    \"\"\"Compute the mean squared error between the ranking matrix and predictions.\"\"\"\n",
    "    A_pred, valid_indices = get_predictions(X_valid)\n",
    "    losses = np.square(X_valid - A_pred)\n",
    "    losses = [losses[i,j] for (i, j) in valid_indices]\n",
    "    mean_loss = np.mean(losses)\n",
    "    return mean_loss\n",
    "\n",
    "compute_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache positions of nonempty indices for training\n",
    "\n",
    "train_indices_perline = [[] for i_ in range(10000)]\n",
    "for i, j in valid_indices:\n",
    "    train_indices_perline[i].append((i, j))\n",
    "\n",
    "for line in train_indices_perline:\n",
    "    assert line\n",
    "assert len(train_indices_perline) == 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It 0 Avg loss: 16.2103\n",
      "It 1000 Avg loss: 3.7257\n",
      "Mean loss: 1.6864\n",
      "It 2000 Avg loss: 1.5205\n",
      "Mean loss: 1.1628\n",
      "It 3000 Avg loss: 1.2870\n",
      "Mean loss: 1.0507\n",
      "It 4000 Avg loss: 1.2396\n",
      "Mean loss: 1.0978\n",
      "It 5000 Avg loss: 1.2203\n",
      "Mean loss: 1.0435\n",
      "It 6000 Avg loss: 1.2128\n",
      "Mean loss: 1.0473\n",
      "It 7000 Avg loss: 1.1953\n",
      "Mean loss: 1.0666\n",
      "It 8000 Avg loss: 1.1910\n",
      "Mean loss: 1.0543\n",
      "It 9000 Avg loss: 1.1856\n",
      "Mean loss: 1.0421\n",
      "It 10000 Avg loss: 1.1771\n",
      "Mean loss: 1.0431\n",
      "It 11000 Avg loss: 1.1758\n",
      "Mean loss: 1.0432\n",
      "It 12000 Avg loss: 1.1736\n",
      "Mean loss: 1.0652\n",
      "It 13000 Avg loss: 1.1674\n",
      "Mean loss: 1.0448\n",
      "It 14000 Avg loss: 1.1608\n",
      "Mean loss: 1.0384\n",
      "It 15000 Avg loss: 1.1661\n",
      "Mean loss: 1.0405\n",
      "It 16000 Avg loss: 1.1597\n",
      "Mean loss: 1.0367\n",
      "It 17000 Avg loss: 1.1577\n",
      "Mean loss: 1.0477\n",
      "It 18000 Avg loss: 1.1513\n",
      "Mean loss: 1.0445\n",
      "It 19000 Avg loss: 1.1498\n",
      "Mean loss: 1.0560\n",
      "It 20000 Avg loss: 1.1475\n",
      "Mean loss: 1.0458\n",
      "It 21000 Avg loss: 1.1433\n",
      "Mean loss: 1.0398\n",
      "It 22000 Avg loss: 1.1397\n",
      "Mean loss: 1.0435\n",
      "It 23000 Avg loss: 1.1381\n",
      "Mean loss: 1.0489\n",
      "It 24000 Avg loss: 1.1371\n",
      "Mean loss: 1.0301\n",
      "It 25000 Avg loss: 1.1385\n",
      "Mean loss: 1.0377\n",
      "It 26000 Avg loss: 1.1317\n",
      "Mean loss: 1.0317\n",
      "It 27000 Avg loss: 1.1329\n",
      "Mean loss: 1.0348\n",
      "It 28000 Avg loss: 1.1282\n",
      "Mean loss: 1.0311\n",
      "It 29000 Avg loss: 1.1250\n",
      "Mean loss: 1.0276\n",
      "It 30000 Avg loss: 1.1225\n",
      "Mean loss: 1.0322\n",
      "It 31000 Avg loss: 1.1198\n",
      "Mean loss: 1.0332\n",
      "It 32000 Avg loss: 1.1224\n",
      "Mean loss: 1.0355\n",
      "It 33000 Avg loss: 1.1169\n",
      "Mean loss: 1.0313\n",
      "It 34000 Avg loss: 1.1174\n",
      "Mean loss: 1.0186\n",
      "It 35000 Avg loss: 1.1143\n",
      "Mean loss: 1.0187\n",
      "It 36000 Avg loss: 1.1119\n",
      "Mean loss: 1.0238\n",
      "It 37000 Avg loss: 1.1058\n",
      "Mean loss: 1.0304\n",
      "It 38000 Avg loss: 1.1066\n",
      "Mean loss: 1.0229\n",
      "It 39000 Avg loss: 1.1050\n",
      "Mean loss: 1.0237\n",
      "It 40000 Avg loss: 1.1020\n",
      "Mean loss: 1.0239\n",
      "It 41000 Avg loss: 1.0991\n",
      "Mean loss: 1.0205\n",
      "It 42000 Avg loss: 1.1006\n",
      "Mean loss: 1.0135\n",
      "It 43000 Avg loss: 1.0999\n",
      "Mean loss: 1.0196\n",
      "It 44000 Avg loss: 1.0953\n",
      "Mean loss: 1.0243\n",
      "It 45000 Avg loss: 1.0941\n",
      "Mean loss: 1.0166\n",
      "It 46000 Avg loss: 1.0975\n",
      "Mean loss: 1.0293\n",
      "It 47000 Avg loss: 1.0907\n",
      "Mean loss: 1.0173\n",
      "It 48000 Avg loss: 1.0896\n",
      "Mean loss: 1.0164\n",
      "It 49000 Avg loss: 1.0869\n",
      "Mean loss: 1.0118\n",
      "It 50000 Avg loss: 1.0861\n",
      "Mean loss: 1.0177\n",
      "It 51000 Avg loss: 1.0876\n",
      "Mean loss: 1.0183\n",
      "It 52000 Avg loss: 1.0845\n",
      "Mean loss: 1.0119\n",
      "It 53000 Avg loss: 1.0814\n",
      "Mean loss: 1.0278\n",
      "It 54000 Avg loss: 1.0790\n",
      "Mean loss: 1.0133\n",
      "It 55000 Avg loss: 1.0783\n",
      "Mean loss: 1.0110\n",
      "It 56000 Avg loss: 1.0767\n",
      "Mean loss: 1.0185\n",
      "It 57000 Avg loss: 1.0762\n",
      "Mean loss: 1.0165\n",
      "It 58000 Avg loss: 1.0773\n",
      "Mean loss: 1.0124\n",
      "It 59000 Avg loss: 1.0740\n",
      "Mean loss: 1.0210\n",
      "It 60000 Avg loss: 1.0731\n",
      "Mean loss: 1.0168\n",
      "It 61000 Avg loss: 1.0707\n",
      "Mean loss: 1.0114\n",
      "It 62000 Avg loss: 1.0713\n",
      "Mean loss: 1.0084\n",
      "It 63000 Avg loss: 1.0690\n",
      "Mean loss: 1.0103\n",
      "It 64000 Avg loss: 1.0668\n",
      "Mean loss: 1.0075\n",
      "It 65000 Avg loss: 1.0650\n",
      "Mean loss: 1.0161\n",
      "It 66000 Avg loss: 1.0654\n",
      "Mean loss: 1.0077\n",
      "It 67000 Avg loss: 1.0651\n",
      "Mean loss: 1.0072\n",
      "It 68000 Avg loss: 1.0608\n",
      "Mean loss: 1.0097\n",
      "It 69000 Avg loss: 1.0597\n",
      "Mean loss: 1.0157\n",
      "It 70000 Avg loss: 1.0589\n",
      "Mean loss: 1.0115\n",
      "It 71000 Avg loss: 1.0567\n",
      "Mean loss: 1.0068\n",
      "It 72000 Avg loss: 1.0552\n",
      "Mean loss: 1.0063\n",
      "It 73000 Avg loss: 1.0555\n",
      "Mean loss: 1.0046\n",
      "It 74000 Avg loss: 1.0555\n",
      "Mean loss: 1.0083\n",
      "It 75000 Avg loss: 1.0549\n",
      "Mean loss: 1.0053\n",
      "It 76000 Avg loss: 1.0556\n",
      "Mean loss: 1.0121\n",
      "It 77000 Avg loss: 1.0555\n",
      "Mean loss: 1.0082\n",
      "It 78000 Avg loss: 1.0525\n",
      "Mean loss: 1.0076\n",
      "It 79000 Avg loss: 1.0496\n",
      "Mean loss: 1.0013\n",
      "It 80000 Avg loss: 1.0514\n",
      "Mean loss: 1.0148\n",
      "It 81000 Avg loss: 1.0497\n",
      "Mean loss: 1.0058\n",
      "It 82000 Avg loss: 1.0496\n",
      "Mean loss: 1.0032\n",
      "It 83000 Avg loss: 1.0506\n",
      "Mean loss: 1.0117\n",
      "It 84000 Avg loss: 1.0428\n",
      "Mean loss: 1.0050\n",
      "It 85000 Avg loss: 1.0495\n",
      "Mean loss: 1.0032\n",
      "It 86000 Avg loss: 1.0446\n",
      "Mean loss: 0.9987\n",
      "It 87000 Avg loss: 1.0425\n",
      "Mean loss: 0.9989\n",
      "It 88000 Avg loss: 1.0430\n",
      "Mean loss: 0.9991\n",
      "It 89000 Avg loss: 1.0386\n",
      "Mean loss: 0.9989\n",
      "It 90000 Avg loss: 1.0410\n",
      "Mean loss: 0.9995\n",
      "It 91000 Avg loss: 1.0375\n",
      "Mean loss: 0.9993\n",
      "It 92000 Avg loss: 1.0402\n",
      "Mean loss: 0.9968\n",
      "It 93000 Avg loss: 1.0349\n",
      "Mean loss: 1.0025\n",
      "It 94000 Avg loss: 1.0348\n",
      "Mean loss: 1.0025\n",
      "It 95000 Avg loss: 1.0355\n",
      "Mean loss: 0.9969\n",
      "It 96000 Avg loss: 1.0327\n",
      "Mean loss: 1.0009\n",
      "It 97000 Avg loss: 1.0353\n",
      "Mean loss: 0.9981\n",
      "It 98000 Avg loss: 1.0351\n",
      "Mean loss: 0.9984\n",
      "It 99000 Avg loss: 1.0308\n",
      "Mean loss: 1.0007\n",
      "It 100000 Avg loss: 1.0296\n",
      "Mean loss: 0.9988\n",
      "It 101000 Avg loss: 1.0299\n",
      "Mean loss: 1.0010\n",
      "It 102000 Avg loss: 1.0294\n",
      "Mean loss: 0.9976\n",
      "It 103000 Avg loss: 1.0290\n",
      "Mean loss: 0.9950\n",
      "It 104000 Avg loss: 1.0317\n",
      "Mean loss: 0.9951\n",
      "It 105000 Avg loss: 1.0281\n",
      "Mean loss: 0.9959\n",
      "It 106000 Avg loss: 1.0231\n",
      "Mean loss: 0.9967\n",
      "It 107000 Avg loss: 1.0231\n",
      "Mean loss: 0.9971\n",
      "It 108000 Avg loss: 1.0225\n",
      "Mean loss: 0.9975\n",
      "It 109000 Avg loss: 1.0243\n",
      "Mean loss: 0.9945\n",
      "It 110000 Avg loss: 1.0269\n",
      "Mean loss: 0.9980\n",
      "It 111000 Avg loss: 1.0206\n",
      "Mean loss: 0.9931\n",
      "It 112000 Avg loss: 1.0188\n",
      "Mean loss: 0.9936\n",
      "It 113000 Avg loss: 1.0240\n",
      "Mean loss: 0.9935\n",
      "It 114000 Avg loss: 1.0193\n",
      "Mean loss: 0.9916\n",
      "It 115000 Avg loss: 1.0198\n",
      "Mean loss: 0.9945\n",
      "It 116000 Avg loss: 1.0193\n",
      "Mean loss: 0.9946\n",
      "It 117000 Avg loss: 1.0226\n",
      "Mean loss: 0.9967\n",
      "It 118000 Avg loss: 1.0196\n",
      "Mean loss: 0.9945\n",
      "It 119000 Avg loss: 1.0191\n",
      "Mean loss: 0.9905\n",
      "It 120000 Avg loss: 1.0175\n",
      "Mean loss: 0.9968\n",
      "It 121000 Avg loss: 1.0202\n",
      "Mean loss: 0.9971\n",
      "It 122000 Avg loss: 1.0171\n",
      "Mean loss: 0.9950\n",
      "It 123000 Avg loss: 1.0152\n",
      "Mean loss: 0.9946\n",
      "It 124000 Avg loss: 1.0125\n",
      "Mean loss: 0.9953\n",
      "It 125000 Avg loss: 1.0144\n",
      "Mean loss: 0.9907\n",
      "It 126000 Avg loss: 1.0113\n",
      "Mean loss: 0.9916\n",
      "It 127000 Avg loss: 1.0120\n",
      "Mean loss: 0.9964\n",
      "It 128000 Avg loss: 1.0115\n",
      "Mean loss: 0.9904\n",
      "It 129000 Avg loss: 1.0123\n",
      "Mean loss: 0.9926\n",
      "It 130000 Avg loss: 1.0116\n",
      "Mean loss: 0.9933\n",
      "It 131000 Avg loss: 1.0108\n",
      "Mean loss: 0.9918\n",
      "It 132000 Avg loss: 1.0081\n",
      "Mean loss: 0.9919\n",
      "It 133000 Avg loss: 1.0095\n",
      "Mean loss: 0.9881\n",
      "It 134000 Avg loss: 1.0134\n",
      "Mean loss: 0.9895\n",
      "It 135000 Avg loss: 1.0077\n",
      "Mean loss: 0.9879\n",
      "It 136000 Avg loss: 1.0085\n",
      "Mean loss: 0.9918\n",
      "It 137000 Avg loss: 1.0066\n",
      "Mean loss: 0.9942\n",
      "It 138000 Avg loss: 1.0076\n",
      "Mean loss: 0.9898\n",
      "It 139000 Avg loss: 1.0079\n",
      "Mean loss: 0.9893\n",
      "It 140000 Avg loss: 1.0072\n",
      "Mean loss: 0.9901\n",
      "It 141000 Avg loss: 1.0082\n",
      "Mean loss: 0.9879\n",
      "It 142000 Avg loss: 1.0063\n",
      "Mean loss: 0.9893\n",
      "It 143000 Avg loss: 1.0044\n",
      "Mean loss: 0.9888\n",
      "It 144000 Avg loss: 1.0052\n",
      "Mean loss: 0.9884\n",
      "It 145000 Avg loss: 1.0054\n",
      "Mean loss: 0.9874\n",
      "It 146000 Avg loss: 1.0044\n",
      "Mean loss: 0.9905\n",
      "It 147000 Avg loss: 1.0048\n",
      "Mean loss: 0.9890\n",
      "It 148000 Avg loss: 1.0020\n",
      "Mean loss: 0.9888\n",
      "It 149000 Avg loss: 1.0017\n",
      "Mean loss: 0.9876\n",
      "It 150000 Avg loss: 1.0027\n",
      "Mean loss: 0.9941\n",
      "It 151000 Avg loss: 1.0018\n",
      "Mean loss: 0.9898\n",
      "It 152000 Avg loss: 0.9979\n",
      "Mean loss: 0.9884\n",
      "It 153000 Avg loss: 1.0014\n",
      "Mean loss: 0.9878\n",
      "It 154000 Avg loss: 1.0027\n",
      "Mean loss: 0.9877\n",
      "It 155000 Avg loss: 0.9992\n",
      "Mean loss: 0.9898\n",
      "It 156000 Avg loss: 0.9953\n",
      "Mean loss: 0.9894\n",
      "It 157000 Avg loss: 1.0011\n",
      "Mean loss: 0.9905\n",
      "It 158000 Avg loss: 0.9973\n",
      "Mean loss: 0.9888\n",
      "It 159000 Avg loss: 0.9969\n",
      "Mean loss: 0.9889\n",
      "It 160000 Avg loss: 0.9988\n",
      "Mean loss: 0.9874\n",
      "It 161000 Avg loss: 0.9974\n",
      "Mean loss: 0.9889\n",
      "It 162000 Avg loss: 0.9980\n",
      "Mean loss: 0.9888\n",
      "It 163000 Avg loss: 0.9947\n",
      "Mean loss: 0.9872\n",
      "It 164000 Avg loss: 0.9969\n",
      "Mean loss: 0.9897\n",
      "It 165000 Avg loss: 0.9947\n",
      "Mean loss: 0.9841\n",
      "It 166000 Avg loss: 0.9940\n",
      "Mean loss: 0.9881\n",
      "It 167000 Avg loss: 0.9961\n",
      "Mean loss: 0.9874\n",
      "It 168000 Avg loss: 0.9949\n",
      "Mean loss: 0.9897\n",
      "It 169000 Avg loss: 0.9907\n",
      "Mean loss: 0.9863\n",
      "It 170000 Avg loss: 0.9940\n",
      "Mean loss: 0.9866\n",
      "It 171000 Avg loss: 0.9942\n",
      "Mean loss: 0.9877\n",
      "It 172000 Avg loss: 0.9950\n",
      "Mean loss: 0.9871\n",
      "It 173000 Avg loss: 0.9914\n",
      "Mean loss: 0.9900\n",
      "It 174000 Avg loss: 0.9935\n",
      "Mean loss: 0.9858\n",
      "It 175000 Avg loss: 0.9922\n",
      "Mean loss: 0.9886\n",
      "It 176000 Avg loss: 0.9922\n",
      "Mean loss: 0.9867\n",
      "It 177000 Avg loss: 0.9899\n",
      "Mean loss: 0.9853\n",
      "It 178000 Avg loss: 0.9919\n",
      "Mean loss: 0.9864\n",
      "It 179000 Avg loss: 0.9880\n",
      "Mean loss: 0.9844\n",
      "It 180000 Avg loss: 0.9949\n",
      "Mean loss: 0.9863\n",
      "It 181000 Avg loss: 0.9899\n",
      "Mean loss: 0.9889\n",
      "It 182000 Avg loss: 0.9887\n",
      "Mean loss: 0.9913\n",
      "It 183000 Avg loss: 0.9906\n",
      "Mean loss: 0.9868\n",
      "It 184000 Avg loss: 0.9899\n",
      "Mean loss: 0.9850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It 185000 Avg loss: 0.9867\n",
      "Mean loss: 0.9855\n",
      "It 186000 Avg loss: 0.9848\n",
      "Mean loss: 0.9862\n",
      "It 187000 Avg loss: 0.9874\n",
      "Mean loss: 0.9870\n",
      "It 188000 Avg loss: 0.9880\n",
      "Mean loss: 0.9854\n",
      "It 189000 Avg loss: 0.9861\n",
      "Mean loss: 0.9858\n",
      "It 190000 Avg loss: 0.9890\n",
      "Mean loss: 0.9864\n",
      "It 191000 Avg loss: 0.9837\n",
      "Mean loss: 0.9872\n",
      "It 192000 Avg loss: 0.9859\n",
      "Mean loss: 0.9849\n",
      "It 193000 Avg loss: 0.9848\n",
      "Mean loss: 0.9851\n",
      "It 194000 Avg loss: 0.9881\n",
      "Mean loss: 0.9851\n",
      "It 195000 Avg loss: 0.9808\n",
      "Mean loss: 0.9859\n",
      "It 196000 Avg loss: 0.9859\n",
      "Mean loss: 0.9872\n",
      "It 197000 Avg loss: 0.9834\n",
      "Mean loss: 0.9847\n",
      "It 198000 Avg loss: 0.9810\n",
      "Mean loss: 0.9860\n",
      "It 199000 Avg loss: 0.9854\n",
      "Mean loss: 0.9857\n",
      "It 200000 Avg loss: 0.9841\n",
      "Mean loss: 0.9871\n",
      "It 201000 Avg loss: 0.9853\n",
      "Mean loss: 0.9862\n",
      "It 202000 Avg loss: 0.9803\n",
      "Mean loss: 0.9838\n",
      "It 203000 Avg loss: 0.9846\n",
      "Mean loss: 0.9846\n",
      "It 204000 Avg loss: 0.9808\n",
      "Mean loss: 0.9835\n",
      "It 205000 Avg loss: 0.9852\n",
      "Mean loss: 0.9828\n",
      "It 206000 Avg loss: 0.9847\n",
      "Mean loss: 0.9845\n",
      "It 207000 Avg loss: 0.9843\n",
      "Mean loss: 0.9859\n",
      "It 208000 Avg loss: 0.9813\n",
      "Mean loss: 0.9821\n",
      "It 209000 Avg loss: 0.9817\n",
      "Mean loss: 0.9826\n",
      "It 210000 Avg loss: 0.9834\n",
      "Mean loss: 0.9820\n",
      "It 211000 Avg loss: 0.9802\n",
      "Mean loss: 0.9823\n",
      "It 212000 Avg loss: 0.9817\n",
      "Mean loss: 0.9847\n",
      "It 213000 Avg loss: 0.9800\n",
      "Mean loss: 0.9849\n",
      "It 214000 Avg loss: 0.9805\n",
      "Mean loss: 0.9840\n",
      "It 215000 Avg loss: 0.9791\n",
      "Mean loss: 0.9829\n",
      "It 216000 Avg loss: 0.9832\n",
      "Mean loss: 0.9844\n",
      "It 217000 Avg loss: 0.9807\n",
      "Mean loss: 0.9849\n",
      "It 218000 Avg loss: 0.9812\n",
      "Mean loss: 0.9851\n",
      "It 219000 Avg loss: 0.9825\n",
      "Mean loss: 0.9823\n",
      "It 220000 Avg loss: 0.9808\n",
      "Mean loss: 0.9824\n",
      "It 221000 Avg loss: 0.9777\n",
      "Mean loss: 0.9865\n",
      "It 222000 Avg loss: 0.9792\n",
      "Mean loss: 0.9823\n",
      "It 223000 Avg loss: 0.9788\n",
      "Mean loss: 0.9823\n",
      "It 224000 Avg loss: 0.9793\n",
      "Mean loss: 0.9819\n",
      "It 225000 Avg loss: 0.9791\n",
      "Mean loss: 0.9813\n",
      "It 226000 Avg loss: 0.9784\n",
      "Mean loss: 0.9858\n",
      "It 227000 Avg loss: 0.9787\n",
      "Mean loss: 0.9850\n",
      "It 228000 Avg loss: 0.9783\n",
      "Mean loss: 0.9854\n",
      "It 229000 Avg loss: 0.9778\n",
      "Mean loss: 0.9816\n",
      "It 230000 Avg loss: 0.9759\n",
      "Mean loss: 0.9846\n",
      "It 231000 Avg loss: 0.9753\n",
      "Mean loss: 0.9838\n",
      "It 232000 Avg loss: 0.9734\n",
      "Mean loss: 0.9802\n",
      "It 233000 Avg loss: 0.9786\n",
      "Mean loss: 0.9821\n",
      "It 234000 Avg loss: 0.9755\n",
      "Mean loss: 0.9819\n",
      "It 235000 Avg loss: 0.9758\n",
      "Mean loss: 0.9822\n",
      "It 236000 Avg loss: 0.9761\n",
      "Mean loss: 0.9849\n",
      "It 237000 Avg loss: 0.9760\n",
      "Mean loss: 0.9836\n",
      "It 238000 Avg loss: 0.9753\n",
      "Mean loss: 0.9826\n",
      "It 239000 Avg loss: 0.9797\n",
      "Mean loss: 0.9825\n",
      "It 240000 Avg loss: 0.9752\n",
      "Mean loss: 0.9810\n",
      "It 241000 Avg loss: 0.9769\n",
      "Mean loss: 0.9831\n",
      "It 242000 Avg loss: 0.9769\n",
      "Mean loss: 0.9802\n",
      "It 243000 Avg loss: 0.9772\n",
      "Mean loss: 0.9812\n",
      "It 244000 Avg loss: 0.9730\n",
      "Mean loss: 0.9829\n",
      "It 245000 Avg loss: 0.9736\n",
      "Mean loss: 0.9817\n",
      "It 246000 Avg loss: 0.9751\n",
      "Mean loss: 0.9833\n",
      "It 247000 Avg loss: 0.9752\n",
      "Mean loss: 0.9828\n",
      "It 248000 Avg loss: 0.9736\n",
      "Mean loss: 0.9818\n",
      "It 249000 Avg loss: 0.9774\n",
      "Mean loss: 0.9849\n",
      "It 250000 Avg loss: 0.9764\n",
      "Mean loss: 0.9832\n",
      "It 251000 Avg loss: 0.9737\n",
      "Mean loss: 0.9829\n",
      "It 252000 Avg loss: 0.9737\n",
      "Mean loss: 0.9834\n",
      "It 253000 Avg loss: 0.9729\n",
      "Mean loss: 0.9802\n",
      "It 254000 Avg loss: 0.9733\n",
      "Mean loss: 0.9803\n",
      "It 255000 Avg loss: 0.9720\n",
      "Mean loss: 0.9822\n",
      "It 256000 Avg loss: 0.9727\n",
      "Mean loss: 0.9818\n",
      "It 257000 Avg loss: 0.9718\n",
      "Mean loss: 0.9802\n",
      "It 258000 Avg loss: 0.9724\n",
      "Mean loss: 0.9829\n",
      "It 259000 Avg loss: 0.9731\n",
      "Mean loss: 0.9820\n",
      "It 260000 Avg loss: 0.9730\n",
      "Mean loss: 0.9832\n",
      "It 261000 Avg loss: 0.9704\n",
      "Mean loss: 0.9806\n",
      "It 262000 Avg loss: 0.9715\n",
      "Mean loss: 0.9809\n",
      "It 263000 Avg loss: 0.9682\n",
      "Mean loss: 0.9823\n",
      "It 264000 Avg loss: 0.9742\n",
      "Mean loss: 0.9818\n",
      "It 265000 Avg loss: 0.9735\n",
      "Mean loss: 0.9824\n",
      "It 266000 Avg loss: 0.9714\n",
      "Mean loss: 0.9812\n",
      "It 267000 Avg loss: 0.9700\n",
      "Mean loss: 0.9792\n",
      "It 268000 Avg loss: 0.9714\n",
      "Mean loss: 0.9802\n",
      "It 269000 Avg loss: 0.9703\n",
      "Mean loss: 0.9812\n",
      "It 270000 Avg loss: 0.9728\n",
      "Mean loss: 0.9824\n",
      "It 271000 Avg loss: 0.9707\n",
      "Mean loss: 0.9833\n",
      "It 272000 Avg loss: 0.9734\n",
      "Mean loss: 0.9821\n",
      "It 273000 Avg loss: 0.9714\n",
      "Mean loss: 0.9832\n",
      "It 274000 Avg loss: 0.9702\n",
      "Mean loss: 0.9839\n",
      "It 275000 Avg loss: 0.9686\n",
      "Mean loss: 0.9805\n",
      "It 276000 Avg loss: 0.9699\n",
      "Mean loss: 0.9792\n",
      "It 277000 Avg loss: 0.9703\n",
      "Mean loss: 0.9805\n",
      "It 278000 Avg loss: 0.9685\n",
      "Mean loss: 0.9806\n",
      "It 279000 Avg loss: 0.9690\n",
      "Mean loss: 0.9828\n",
      "It 280000 Avg loss: 0.9686\n",
      "Mean loss: 0.9802\n",
      "It 281000 Avg loss: 0.9680\n",
      "Mean loss: 0.9821\n",
      "It 282000 Avg loss: 0.9679\n",
      "Mean loss: 0.9796\n",
      "It 283000 Avg loss: 0.9671\n",
      "Mean loss: 0.9794\n",
      "It 284000 Avg loss: 0.9703\n",
      "Mean loss: 0.9806\n",
      "It 285000 Avg loss: 0.9685\n",
      "Mean loss: 0.9810\n",
      "It 286000 Avg loss: 0.9686\n",
      "Mean loss: 0.9812\n",
      "It 287000 Avg loss: 0.9675\n",
      "Mean loss: 0.9797\n",
      "It 288000 Avg loss: 0.9715\n",
      "Mean loss: 0.9797\n",
      "It 289000 Avg loss: 0.9675\n",
      "Mean loss: 0.9799\n",
      "It 290000 Avg loss: 0.9675\n",
      "Mean loss: 0.9791\n",
      "It 291000 Avg loss: 0.9661\n",
      "Mean loss: 0.9812\n",
      "It 292000 Avg loss: 0.9656\n",
      "Mean loss: 0.9779\n",
      "It 293000 Avg loss: 0.9667\n",
      "Mean loss: 0.9832\n",
      "It 294000 Avg loss: 0.9687\n",
      "Mean loss: 0.9796\n",
      "It 295000 Avg loss: 0.9650\n",
      "Mean loss: 0.9795\n",
      "It 296000 Avg loss: 0.9668\n",
      "Mean loss: 0.9808\n",
      "It 297000 Avg loss: 0.9644\n",
      "Mean loss: 0.9791\n",
      "It 298000 Avg loss: 0.9655\n",
      "Mean loss: 0.9808\n",
      "It 299000 Avg loss: 0.9661\n",
      "Mean loss: 0.9815\n",
      "It 300000 Avg loss: 0.9664\n",
      "Mean loss: 0.9798\n",
      "It 301000 Avg loss: 0.9699\n",
      "Mean loss: 0.9804\n",
      "It 302000 Avg loss: 0.9665\n",
      "Mean loss: 0.9801\n",
      "It 303000 Avg loss: 0.9681\n",
      "Mean loss: 0.9811\n",
      "It 304000 Avg loss: 0.9665\n",
      "Mean loss: 0.9791\n",
      "It 305000 Avg loss: 0.9640\n",
      "Mean loss: 0.9792\n",
      "It 306000 Avg loss: 0.9658\n",
      "Mean loss: 0.9800\n",
      "It 307000 Avg loss: 0.9637\n",
      "Mean loss: 0.9806\n",
      "It 308000 Avg loss: 0.9655\n",
      "Mean loss: 0.9793\n",
      "It 309000 Avg loss: 0.9662\n",
      "Mean loss: 0.9801\n",
      "It 310000 Avg loss: 0.9647\n",
      "Mean loss: 0.9805\n",
      "It 311000 Avg loss: 0.9644\n",
      "Mean loss: 0.9782\n",
      "It 312000 Avg loss: 0.9676\n",
      "Mean loss: 0.9795\n",
      "It 313000 Avg loss: 0.9700\n",
      "Mean loss: 0.9811\n",
      "It 314000 Avg loss: 0.9603\n",
      "Mean loss: 0.9774\n",
      "It 315000 Avg loss: 0.9627\n",
      "Mean loss: 0.9780\n",
      "It 316000 Avg loss: 0.9605\n",
      "Mean loss: 0.9777\n",
      "It 317000 Avg loss: 0.9657\n",
      "Mean loss: 0.9783\n",
      "It 318000 Avg loss: 0.9637\n",
      "Mean loss: 0.9810\n",
      "It 319000 Avg loss: 0.9663\n",
      "Mean loss: 0.9791\n",
      "It 320000 Avg loss: 0.9611\n",
      "Mean loss: 0.9780\n",
      "It 321000 Avg loss: 0.9670\n",
      "Mean loss: 0.9792\n",
      "It 322000 Avg loss: 0.9621\n",
      "Mean loss: 0.9790\n",
      "It 323000 Avg loss: 0.9632\n",
      "Mean loss: 0.9780\n",
      "It 324000 Avg loss: 0.9615\n",
      "Mean loss: 0.9796\n",
      "It 325000 Avg loss: 0.9626\n",
      "Mean loss: 0.9776\n",
      "It 326000 Avg loss: 0.9653\n",
      "Mean loss: 0.9788\n",
      "It 327000 Avg loss: 0.9638\n",
      "Mean loss: 0.9807\n",
      "It 328000 Avg loss: 0.9602\n",
      "Mean loss: 0.9783\n",
      "It 329000 Avg loss: 0.9620\n",
      "Mean loss: 0.9784\n",
      "It 330000 Avg loss: 0.9607\n",
      "Mean loss: 0.9775\n",
      "It 331000 Avg loss: 0.9638\n",
      "Mean loss: 0.9779\n",
      "It 332000 Avg loss: 0.9649\n",
      "Mean loss: 0.9786\n",
      "It 333000 Avg loss: 0.9601\n",
      "Mean loss: 0.9790\n",
      "It 334000 Avg loss: 0.9615\n",
      "Mean loss: 0.9783\n",
      "It 335000 Avg loss: 0.9610\n",
      "Mean loss: 0.9778\n",
      "It 336000 Avg loss: 0.9626\n",
      "Mean loss: 0.9772\n",
      "It 337000 Avg loss: 0.9613\n",
      "Mean loss: 0.9772\n",
      "It 338000 Avg loss: 0.9617\n",
      "Mean loss: 0.9787\n",
      "It 339000 Avg loss: 0.9639\n",
      "Mean loss: 0.9794\n",
      "It 340000 Avg loss: 0.9643\n",
      "Mean loss: 0.9788\n",
      "It 341000 Avg loss: 0.9642\n",
      "Mean loss: 0.9789\n",
      "It 342000 Avg loss: 0.9639\n",
      "Mean loss: 0.9773\n",
      "It 343000 Avg loss: 0.9625\n",
      "Mean loss: 0.9800\n",
      "It 344000 Avg loss: 0.9640\n",
      "Mean loss: 0.9775\n",
      "It 345000 Avg loss: 0.9616\n",
      "Mean loss: 0.9772\n",
      "It 346000 Avg loss: 0.9567\n",
      "Mean loss: 0.9771\n",
      "It 347000 Avg loss: 0.9591\n",
      "Mean loss: 0.9792\n",
      "It 348000 Avg loss: 0.9579\n",
      "Mean loss: 0.9784\n",
      "It 349000 Avg loss: 0.9613\n",
      "Mean loss: 0.9774\n",
      "It 350000 Avg loss: 0.9616\n",
      "Mean loss: 0.9780\n",
      "It 351000 Avg loss: 0.9618\n",
      "Mean loss: 0.9761\n",
      "It 352000 Avg loss: 0.9602\n",
      "Mean loss: 0.9767\n",
      "It 353000 Avg loss: 0.9614\n",
      "Mean loss: 0.9783\n",
      "It 354000 Avg loss: 0.9618\n",
      "Mean loss: 0.9779\n",
      "It 355000 Avg loss: 0.9606\n",
      "Mean loss: 0.9798\n",
      "It 356000 Avg loss: 0.9605\n",
      "Mean loss: 0.9777\n",
      "It 357000 Avg loss: 0.9632\n",
      "Mean loss: 0.9772\n",
      "It 358000 Avg loss: 0.9600\n",
      "Mean loss: 0.9785\n",
      "It 359000 Avg loss: 0.9596\n",
      "Mean loss: 0.9783\n",
      "It 360000 Avg loss: 0.9616\n",
      "Mean loss: 0.9768\n",
      "It 361000 Avg loss: 0.9590\n",
      "Mean loss: 0.9763\n",
      "It 362000 Avg loss: 0.9630\n",
      "Mean loss: 0.9774\n",
      "It 363000 Avg loss: 0.9613\n",
      "Mean loss: 0.9770\n",
      "It 364000 Avg loss: 0.9586\n",
      "Mean loss: 0.9760\n",
      "It 365000 Avg loss: 0.9599\n",
      "Mean loss: 0.9778\n",
      "It 366000 Avg loss: 0.9613\n",
      "Mean loss: 0.9761\n",
      "It 367000 Avg loss: 0.9619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss: 0.9762\n",
      "It 368000 Avg loss: 0.9594\n",
      "Mean loss: 0.9771\n",
      "It 369000 Avg loss: 0.9609\n",
      "Mean loss: 0.9784\n",
      "It 370000 Avg loss: 0.9557\n",
      "Mean loss: 0.9771\n",
      "It 371000 Avg loss: 0.9585\n",
      "Mean loss: 0.9770\n",
      "It 372000 Avg loss: 0.9605\n",
      "Mean loss: 0.9766\n",
      "It 373000 Avg loss: 0.9586\n",
      "Mean loss: 0.9771\n",
      "It 374000 Avg loss: 0.9587\n",
      "Mean loss: 0.9776\n",
      "It 375000 Avg loss: 0.9603\n",
      "Mean loss: 0.9772\n",
      "It 376000 Avg loss: 0.9579\n",
      "Mean loss: 0.9781\n",
      "It 377000 Avg loss: 0.9603\n",
      "Mean loss: 0.9769\n",
      "It 378000 Avg loss: 0.9599\n",
      "Mean loss: 0.9759\n",
      "It 379000 Avg loss: 0.9573\n",
      "Mean loss: 0.9761\n",
      "It 380000 Avg loss: 0.9558\n",
      "Mean loss: 0.9758\n",
      "It 381000 Avg loss: 0.9562\n",
      "Mean loss: 0.9763\n",
      "It 382000 Avg loss: 0.9568\n",
      "Mean loss: 0.9762\n",
      "It 383000 Avg loss: 0.9623\n",
      "Mean loss: 0.9773\n",
      "It 384000 Avg loss: 0.9592\n",
      "Mean loss: 0.9761\n",
      "It 385000 Avg loss: 0.9578\n",
      "Mean loss: 0.9776\n",
      "It 386000 Avg loss: 0.9557\n",
      "Mean loss: 0.9764\n",
      "It 387000 Avg loss: 0.9569\n",
      "Mean loss: 0.9781\n",
      "It 388000 Avg loss: 0.9588\n",
      "Mean loss: 0.9763\n",
      "It 389000 Avg loss: 0.9604\n",
      "Mean loss: 0.9766\n",
      "It 390000 Avg loss: 0.9557\n",
      "Mean loss: 0.9763\n",
      "It 391000 Avg loss: 0.9550\n",
      "Mean loss: 0.9763\n",
      "It 392000 Avg loss: 0.9600\n",
      "Mean loss: 0.9763\n",
      "It 393000 Avg loss: 0.9583\n",
      "Mean loss: 0.9778\n",
      "It 394000 Avg loss: 0.9550\n",
      "Mean loss: 0.9777\n",
      "It 395000 Avg loss: 0.9560\n",
      "Mean loss: 0.9781\n",
      "It 396000 Avg loss: 0.9563\n",
      "Mean loss: 0.9771\n",
      "It 397000 Avg loss: 0.9558\n",
      "Mean loss: 0.9777\n",
      "It 398000 Avg loss: 0.9548\n",
      "Mean loss: 0.9762\n",
      "It 399000 Avg loss: 0.9556\n",
      "Mean loss: 0.9759\n",
      "It 400000 Avg loss: 0.9541\n",
      "Mean loss: 0.9767\n",
      "It 401000 Avg loss: 0.9550\n",
      "Mean loss: 0.9762\n",
      "It 402000 Avg loss: 0.9565\n",
      "Mean loss: 0.9766\n",
      "It 403000 Avg loss: 0.9559\n",
      "Mean loss: 0.9775\n",
      "It 404000 Avg loss: 0.9594\n",
      "Mean loss: 0.9768\n",
      "It 405000 Avg loss: 0.9551\n",
      "Mean loss: 0.9758\n",
      "It 406000 Avg loss: 0.9598\n",
      "Mean loss: 0.9763\n",
      "It 407000 Avg loss: 0.9585\n",
      "Mean loss: 0.9759\n",
      "It 408000 Avg loss: 0.9542\n",
      "Mean loss: 0.9763\n",
      "It 409000 Avg loss: 0.9559\n",
      "Mean loss: 0.9769\n",
      "It 410000 Avg loss: 0.9568\n",
      "Mean loss: 0.9766\n",
      "It 411000 Avg loss: 0.9543\n",
      "Mean loss: 0.9757\n",
      "It 412000 Avg loss: 0.9551\n",
      "Mean loss: 0.9767\n",
      "It 413000 Avg loss: 0.9554\n",
      "Mean loss: 0.9757\n",
      "It 414000 Avg loss: 0.9561\n",
      "Mean loss: 0.9763\n",
      "It 415000 Avg loss: 0.9539\n",
      "Mean loss: 0.9757\n",
      "It 416000 Avg loss: 0.9536\n",
      "Mean loss: 0.9760\n",
      "It 417000 Avg loss: 0.9549\n",
      "Mean loss: 0.9763\n",
      "It 418000 Avg loss: 0.9571\n",
      "Mean loss: 0.9766\n",
      "It 419000 Avg loss: 0.9560\n",
      "Mean loss: 0.9759\n",
      "It 420000 Avg loss: 0.9546\n",
      "Mean loss: 0.9757\n",
      "It 421000 Avg loss: 0.9556\n",
      "Mean loss: 0.9756\n",
      "It 422000 Avg loss: 0.9526\n",
      "Mean loss: 0.9765\n",
      "It 423000 Avg loss: 0.9526\n",
      "Mean loss: 0.9768\n",
      "It 424000 Avg loss: 0.9582\n",
      "Mean loss: 0.9748\n",
      "It 425000 Avg loss: 0.9559\n",
      "Mean loss: 0.9756\n",
      "It 426000 Avg loss: 0.9525\n",
      "Mean loss: 0.9755\n",
      "It 427000 Avg loss: 0.9563\n",
      "Mean loss: 0.9767\n",
      "It 428000 Avg loss: 0.9573\n",
      "Mean loss: 0.9762\n",
      "It 429000 Avg loss: 0.9536\n",
      "Mean loss: 0.9772\n",
      "It 430000 Avg loss: 0.9551\n",
      "Mean loss: 0.9768\n",
      "It 431000 Avg loss: 0.9551\n",
      "Mean loss: 0.9761\n",
      "It 432000 Avg loss: 0.9538\n",
      "Mean loss: 0.9750\n",
      "It 433000 Avg loss: 0.9562\n",
      "Mean loss: 0.9759\n",
      "It 434000 Avg loss: 0.9551\n",
      "Mean loss: 0.9762\n",
      "It 435000 Avg loss: 0.9534\n",
      "Mean loss: 0.9761\n",
      "It 436000 Avg loss: 0.9551\n",
      "Mean loss: 0.9748\n",
      "It 437000 Avg loss: 0.9576\n",
      "Mean loss: 0.9762\n",
      "It 438000 Avg loss: 0.9564\n",
      "Mean loss: 0.9758\n",
      "It 439000 Avg loss: 0.9567\n",
      "Mean loss: 0.9761\n",
      "It 440000 Avg loss: 0.9560\n",
      "Mean loss: 0.9749\n",
      "It 441000 Avg loss: 0.9558\n",
      "Mean loss: 0.9765\n",
      "It 442000 Avg loss: 0.9568\n",
      "Mean loss: 0.9755\n",
      "It 443000 Avg loss: 0.9559\n",
      "Mean loss: 0.9764\n",
      "It 444000 Avg loss: 0.9547\n",
      "Mean loss: 0.9755\n",
      "It 445000 Avg loss: 0.9542\n",
      "Mean loss: 0.9759\n",
      "It 446000 Avg loss: 0.9539\n",
      "Mean loss: 0.9757\n",
      "It 447000 Avg loss: 0.9560\n",
      "Mean loss: 0.9766\n",
      "It 448000 Avg loss: 0.9550\n",
      "Mean loss: 0.9762\n",
      "It 449000 Avg loss: 0.9549\n",
      "Mean loss: 0.9759\n",
      "It 450000 Avg loss: 0.9566\n",
      "Mean loss: 0.9750\n",
      "It 451000 Avg loss: 0.9518\n",
      "Mean loss: 0.9766\n",
      "It 452000 Avg loss: 0.9529\n",
      "Mean loss: 0.9753\n",
      "It 453000 Avg loss: 0.9539\n",
      "Mean loss: 0.9768\n",
      "It 454000 Avg loss: 0.9533\n",
      "Mean loss: 0.9759\n",
      "It 455000 Avg loss: 0.9530\n",
      "Mean loss: 0.9753\n",
      "It 456000 Avg loss: 0.9562\n",
      "Mean loss: 0.9756\n",
      "It 457000 Avg loss: 0.9554\n",
      "Mean loss: 0.9760\n",
      "It 458000 Avg loss: 0.9513\n",
      "Mean loss: 0.9750\n",
      "It 459000 Avg loss: 0.9529\n",
      "Mean loss: 0.9758\n",
      "It 460000 Avg loss: 0.9536\n",
      "Mean loss: 0.9758\n",
      "It 461000 Avg loss: 0.9540\n",
      "Mean loss: 0.9754\n",
      "It 462000 Avg loss: 0.9550\n",
      "Mean loss: 0.9768\n",
      "It 463000 Avg loss: 0.9522\n",
      "Mean loss: 0.9760\n",
      "It 464000 Avg loss: 0.9556\n",
      "Mean loss: 0.9748\n",
      "It 465000 Avg loss: 0.9547\n",
      "Mean loss: 0.9759\n",
      "It 466000 Avg loss: 0.9548\n",
      "Mean loss: 0.9754\n",
      "It 467000 Avg loss: 0.9548\n",
      "Mean loss: 0.9760\n",
      "It 468000 Avg loss: 0.9530\n",
      "Mean loss: 0.9753\n",
      "It 469000 Avg loss: 0.9525\n",
      "Mean loss: 0.9763\n",
      "It 470000 Avg loss: 0.9546\n",
      "Mean loss: 0.9747\n",
      "It 471000 Avg loss: 0.9500\n",
      "Mean loss: 0.9759\n",
      "It 472000 Avg loss: 0.9516\n",
      "Mean loss: 0.9761\n",
      "It 473000 Avg loss: 0.9538\n",
      "Mean loss: 0.9760\n",
      "It 474000 Avg loss: 0.9501\n",
      "Mean loss: 0.9762\n",
      "It 475000 Avg loss: 0.9554\n",
      "Mean loss: 0.9759\n",
      "It 476000 Avg loss: 0.9544\n",
      "Mean loss: 0.9769\n",
      "It 477000 Avg loss: 0.9558\n",
      "Mean loss: 0.9756\n",
      "It 478000 Avg loss: 0.9532\n",
      "Mean loss: 0.9761\n",
      "It 479000 Avg loss: 0.9516\n",
      "Mean loss: 0.9762\n",
      "It 480000 Avg loss: 0.9565\n",
      "Mean loss: 0.9761\n",
      "It 481000 Avg loss: 0.9512\n",
      "Mean loss: 0.9756\n",
      "It 482000 Avg loss: 0.9531\n",
      "Mean loss: 0.9744\n",
      "It 483000 Avg loss: 0.9529\n",
      "Mean loss: 0.9767\n",
      "It 484000 Avg loss: 0.9540\n",
      "Mean loss: 0.9757\n",
      "It 485000 Avg loss: 0.9531\n",
      "Mean loss: 0.9752\n",
      "It 486000 Avg loss: 0.9534\n",
      "Mean loss: 0.9760\n",
      "It 487000 Avg loss: 0.9503\n",
      "Mean loss: 0.9754\n",
      "It 488000 Avg loss: 0.9561\n",
      "Mean loss: 0.9763\n",
      "It 489000 Avg loss: 0.9542\n",
      "Mean loss: 0.9760\n",
      "It 490000 Avg loss: 0.9537\n",
      "Mean loss: 0.9749\n",
      "It 491000 Avg loss: 0.9542\n",
      "Mean loss: 0.9751\n",
      "It 492000 Avg loss: 0.9510\n",
      "Mean loss: 0.9750\n",
      "It 493000 Avg loss: 0.9537\n",
      "Mean loss: 0.9763\n",
      "It 494000 Avg loss: 0.9530\n",
      "Mean loss: 0.9751\n",
      "It 495000 Avg loss: 0.9527\n",
      "Mean loss: 0.9749\n",
      "It 496000 Avg loss: 0.9517\n",
      "Mean loss: 0.9751\n",
      "It 497000 Avg loss: 0.9556\n",
      "Mean loss: 0.9759\n",
      "It 498000 Avg loss: 0.9520\n",
      "Mean loss: 0.9752\n",
      "It 499000 Avg loss: 0.9542\n",
      "Mean loss: 0.9748\n"
     ]
    }
   ],
   "source": [
    "ANNEAL_ALPHA = 0.0\n",
    "NOISE_SCALE = 0.5\n",
    "MAX_STEPS = 500000\n",
    "\n",
    "loss_avg = []\n",
    "\n",
    "for i in range(0, MAX_STEPS):\n",
    "    # randomly sample 32 points from training matrix\n",
    "    model.train()\n",
    "    random_lines = random.sample(range(0, 10000), k=32)\n",
    "    X = X_train[random_lines].todense()\n",
    "    X = torch.tensor(X, dtype=torch.float, device=device)\n",
    "    y_true = X\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    # Important: Add random noise to the input to prevent overfitting\n",
    "    y_preds, KL = model(X + torch.randn(X.shape, device=device) * NOISE_SCALE)\n",
    "    \n",
    "    valid_mask = torch.zeros_like(y_preds, device=device)\n",
    "    for i_ in range(X.shape[0]):\n",
    "        i_real = random_lines[i_]\n",
    "        indices = [j for _,j in train_indices_perline[i_real]]\n",
    "        valid_mask[i_, indices] = 1.0\n",
    "\n",
    "    loss = (y_preds - y_true) ** 2\n",
    "    loss = loss[valid_mask != 0.]\n",
    "    neg_ELBO = loss + ANNEAL_ALPHA * KL\n",
    "    \n",
    "    # update avg loss\n",
    "    loss_avg.insert(0, loss.mean().item())\n",
    "    loss_avg = loss_avg[:1000]\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print(\"It %d Avg loss: %.4f\" % (i, np.mean(loss_avg)))\n",
    "    if i and i % 1000 == 0:\n",
    "        mean_loss = compute_loss()\n",
    "        print(\"Mean loss: %.4f\" % mean_loss)\n",
    "    \n",
    "    neg_ELBO.mean().backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "    opt.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9745764841373259\n"
     ]
    }
   ],
   "source": [
    "mean_loss = compute_loss()\n",
    "print(mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The predicted matrix can also be used as initialization for other models ...\n",
    "import pickle\n",
    "with open(\"array-for-svd.pkl\", \"wb\") as wp:\n",
    "    pickle.dump(get_predictions(X_train)[0], wp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Please check---\n",
      "        Id  Prediction\n",
      "0    r1_c4    3.627194\n",
      "1    r1_c8    3.384989\n",
      "2   r1_c21    2.961046\n",
      "3  r1_c102    3.931744\n",
      "4  r1_c127    3.237733\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def export_and_save(target, preds):\n",
    "    target_rows, target_cols = target.nonzero()\n",
    "    ids = [f\"r{row+1}_c{col+1}\" for row, col in zip(target_rows, target_cols)]\n",
    "    scores = [preds[row, col] for row, col in zip(target_rows, target_cols)]\n",
    "    # Clip scores out of valid range\n",
    "    scores = [score if score <= 5.0 else 5.0 for score in scores]\n",
    "    scores = [score if score >= 1.0 else 1.0 for score in scores]\n",
    "    df = pd.DataFrame({\"Id\": ids, \"Prediction\": scores})\n",
    "    print(\"---Please check---\")\n",
    "    print(df.head())\n",
    "    df.to_csv(\"../../predictions/vae-1.csv\", index=False)\n",
    "\n",
    "export_and_save(X_test, get_predictions(X_test)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1000) 3.384988784790039\n"
     ]
    }
   ],
   "source": [
    "# Check whether we exported the array correctly ...\n",
    "import pickle\n",
    "with open(\"array-for-svd.pkl\", \"rb\") as fp:\n",
    "    arr = pickle.load(fp)\n",
    "    print(arr.shape, arr[0,7])\n",
    "    del arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
