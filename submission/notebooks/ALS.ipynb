{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Requirement already satisfied: scikit-surprise in /anaconda3/lib/python3.7/site-packages (1.1.0)\nRequirement already satisfied: scipy>=1.0.0 in /anaconda3/lib/python3.7/site-packages (from scikit-surprise) (1.4.1)\nRequirement already satisfied: joblib>=0.11 in /anaconda3/lib/python3.7/site-packages (from scikit-surprise) (0.13.2)\nRequirement already satisfied: numpy>=1.11.2 in /anaconda3/lib/python3.7/site-packages (from scikit-surprise) (1.17.2)\nRequirement already satisfied: six>=1.10.0 in /anaconda3/lib/python3.7/site-packages (from scikit-surprise) (1.15.0)\n\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\nYou should consider upgrading via the '/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%pip install scikit-surprise\n",
    "from surprise import AlgoBase, PredictionImpossible, Reader, Dataset, accuracy\n",
    "from surprise.model_selection import train_test_split, cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_raw = pd.read_csv('../data/data-train.csv')\n",
    "\n",
    "# parse rows and columns\n",
    "row_str = data_train_raw['Id'].apply(lambda x: x.split('_')[0])\n",
    "row_id = row_str.apply(lambda x: int(x.split('r')[1]) - 1)\n",
    "col_str = data_train_raw['Id'].apply(lambda x: x.split('_')[1])\n",
    "col_id = col_str.apply(lambda x: int(x.split('c')[1]) - 1)\n",
    "\n",
    "# apply changes\n",
    "data_train_raw['row'] = row_id\n",
    "data_train_raw['col'] = col_id\n",
    "\n",
    "# dataset as data frame\n",
    "data_train_df = data_train_raw.loc[:,['row', 'col', 'Prediction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up surprise dataset\n",
    "reader = Reader()\n",
    "dataset = Dataset.load_from_df(data_train_df[['row', 'col', 'Prediction']], reader)\n",
    "\n",
    "# now set up training and test set, with a test split of 25%\n",
    "trainset, testset = train_test_split(dataset, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "surprise.trainset.Trainset"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "type(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[1, 2, 0],\n       [0, 5, 6],\n       [7, 0, 0]])"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "A = np.array([[1, 2, 0], [0, 5, 6], [7,0,0]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[3., 3., 3.],\n       [3., 3., 3.],\n       [3., 3., 3.]])"
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "A  = np.ones(3)*np.reshape(np.ones(3), (-1, 1))\n",
    "np.sum([, (-1, 1)))\n",
    "np.squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_column_norm_square(M):\n",
    "    return np.sum(np.square(np.linalg.norm(M, axis = 0)))\n",
    "\n",
    "def als_objective(A, P, Q, lamb):\n",
    "    \"\"\"\n",
    "    Least squares with regularization\n",
    "\n",
    "    A: np.array, target matrix\n",
    "    \"\"\"\n",
    "    observed_id = np.nonzero(A)\n",
    "    least_squares = np.sum(np.square(A - P.T@Q)[observed_id]) #extract observed values\n",
    "    regularization = lamb*(sum_column_norm_square(P)+ sum_column_norm_square(Q))\n",
    "    error = (least_squares + regularization)/observed_id[0].shape[0]\n",
    "    return error \n",
    "\n",
    "def als(trainset, k, lamb, tol, max_iter):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    m, n = trainset.n_users, trainset.n_items\n",
    "    # Get rating matrix\n",
    "    A = np.zeros((m, n))\n",
    "    for u, i, r in trainset.all_ratings():\n",
    "        A[u,i] = r\n",
    "    # Initialize P, Q\n",
    "    P = np.ones((k,m)) #user matrix\n",
    "    Q = np.ones((k,n)) #item matrix\n",
    "    Id_k = np.eye(N=k)\n",
    "    # Alternate to optimize\n",
    "    num_iter = 0\n",
    "    while num_iter < max_iter:\n",
    "        ls_error = als_objective(A, P, Q, lamb)\n",
    "        print(\"Iter  {}:  error {}\".format(num_iter, ls_error))\n",
    "        for u in range(m):\n",
    "            obs_items = np.nonzero(A[u, :])\n",
    "            sum_qqT = np.sum([Q[:, i]*np.reshape(Q[:, i], (-1, 1)) for i in obs_items[0]], 0)\n",
    "            P[:, u] = np.squeeze(np.linalg.inv(sum_qqT+lamb*Id_k) @ np.reshape(np.sum([A[u,item]*Q[:, item] for item in obs_items[0]], 0), (-1, 1)))\n",
    "        for i in range(n):\n",
    "            obs_users = np.nonzero(A[:, i])\n",
    "            sum_ppT = np.sum([P[:, u]*np.reshape(P[:, u], (-1, 1)) for u in obs_users[0]], 0)\n",
    "            Q[:, i] = np.squeeze(np.linalg.inv(sum_ppT+lamb*Id_k) @ np.reshape(np.sum([A[u, i]*P[:, u] for u in obs_users[0]], 0), (-1, 1)))\n",
    "        if ls_error <= tol:\n",
    "            break\n",
    "        num_iter += 1\n",
    "    return P, Q\n",
    "\n",
    "class ALS(AlgoBase):\n",
    "    def __init__(self,k = 10, lamb = 0.1, tol  = 0.001):\n",
    "        self.k = k\n",
    "        self.lamb = lamb\n",
    "        self.tol = tol\n",
    "        self.max_iter = 10\n",
    "    def fit(self, trainset):\n",
    "        AlgoBase.fit(self, trainset)\n",
    "\n",
    "        self.P, self.Q = als(self.trainset, self.k, self.lamb, self.tol, self.max_iter)\n",
    "                \n",
    "    def estimate(self, u, i):\n",
    "        return np.clip(np.dot(self.P[:, u], self.Q[:, i]), 1, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Iter  0:  error 2130.33334806064\nIter  1:  error 0.99520393224266\nIter  2:  error 0.9836105320003581\nIter  3:  error 0.6779563555205009\nIter  4:  error 0.3959822180364494\nIter  5:  error 0.3733732188148797\nIter  6:  error 0.35798689132548106\nIter  7:  error 0.34636870445165113\nIter  8:  error 0.3371453628802589\nIter  9:  error 0.3295828352460912\n"
    }
   ],
   "source": [
    "model = ALS(k=50)\n",
    "model.fit(trainset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "RMSE: 1.4130\n"
    }
   ],
   "source": [
    "predictions = model.test(testset)\n",
    "rmse = accuracy.rmse(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}